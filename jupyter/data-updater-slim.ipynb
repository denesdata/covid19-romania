{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from influxdb import DataFrameClient\n",
    "import json\n",
    "%cd /home/jovyan/work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "purge=False\n",
    "# purge=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_annoations=False\n",
    "# process_annoations=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_macro=False\n",
    "process_macro=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_out=False\n",
    "write_out=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_overwrite=False\n",
    "# full_overwrite=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pre-params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0=pd.read_csv('df0.csv').set_index('date')\n",
    "df0.index=pd.to_datetime(df0.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bets=json.loads(open('bets.json','r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity=pd.read_csv('severity.csv').set_index('date')\n",
    "severity.index=pd.to_datetime(severity.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobility=pd.read_csv('mobility.csv').set_index('date')\n",
    "mobility.index=pd.to_datetime(mobility.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobility_mini=pd.read_csv('mobility_mini.csv').set_index('date')\n",
    "mobility_mini.index=pd.to_datetime(mobility_mini.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish DB connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'admin'\n",
    "password = open('auth/influxa.txt','r').read()\n",
    "host='influxdb'\n",
    "port=8086\n",
    "dbname='base'\n",
    "dbname_long='long'\n",
    "protocol = 'line' #'json'\n",
    "client = DataFrameClient(host, port, user, password, dbname)\n",
    "client_long = DataFrameClient(host, port, user, password, dbname_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "if purge:\n",
    "    client.drop_database(dbname)\n",
    "    client.drop_retention_policy(dbname)\n",
    "    client.create_database(dbname)\n",
    "    client.create_retention_policy(dbname, '600d', 1, default=True)\n",
    "    client_long.drop_database(dbname_long)\n",
    "    client_long.drop_retention_policy(dbname_long)\n",
    "    client_long.create_database(dbname_long)\n",
    "    client_long.create_retention_policy(dbname_long, '6000d', 1, default=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "htmlipath='../html/'\n",
    "htmlepath='//myserv-html.er/'\n",
    "htmlepath_other='//mybackupserv-html.er/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles={'HU':\"Magyar\",'RO':'Română','EN':'English'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtitles={titles[t]:t for t in titles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "grafana = \"http://grafana:3000/\"\n",
    "headers = {\n",
    "    'Authorization': 'Bearer '+open('auth/grafana.txt','r').read(),\n",
    "    'Accept': 'application/json',\n",
    "    'Content-Type': 'application/json'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(grafana+'api/folders', headers=headers)\n",
    "folders=json.loads(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_id=[f['id'] for f in folders if f['title']=='My Grafana Folder'][0] #General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(grafana+'api/search?folderIds='+str(folder_id), headers=headers)\n",
    "dashs=json.loads(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "uids={rtitles[d['title']]:d['uid'] for d in dashs if d['title'] in rtitles}\n",
    "iids={rtitles[d['title']]:d['id'] for d in dashs if d['title'] in rtitles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "uids_light={rtitles[d['title'].split(' Light')[0]]:d['uid'] for d in dashs if 'Light' in d['title']}\n",
    "iids_light={rtitles[d['title'].split(' Light')[0]]:d['id'] for d in dashs if 'Light' in d['title']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages=['HU','RO','EN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://docs.google.com/spreadsheets/d/'+open('auth/sheet.txt','r').read()+'/gviz/tq?tqx=out:csv&sheet='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_szotar():\n",
    "    sheet='szotar'\n",
    "    columns=languages+[i+'_description' for i in languages]+[i+'_source' for i in languages]\n",
    "    df=pd.read_csv(url+sheet)\n",
    "    df=df[['ID','UI']+columns]\n",
    "    sheet='minidashboard'\n",
    "    df2=pd.read_csv(url+sheet)\n",
    "    df2=df2[['ID','UI']+columns]\n",
    "    df=pd.concat([df,df2])\n",
    "    szotardf=df.set_index('ID')[columns]\n",
    "    szotar=df.set_index('ID').T.to_dict()\n",
    "    szotarHU=df.set_index('HU',drop=False).T.to_dict()\n",
    "    szotarRO=df.set_index('RO',drop=False).T.to_dict()\n",
    "    szotarEN=df.set_index('EN',drop=False).T.to_dict()\n",
    "    return szotardf,szotar,szotarHU,szotarRO,szotarEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_time_conflicts(series):\n",
    "    ds={}\n",
    "    ts=[]\n",
    "    for d in series:\n",
    "        if d not in ds:\n",
    "            ds[d]=pd.to_datetime(d)\n",
    "            t=(ds[d])\n",
    "        else:\n",
    "            ds[d]=ds[d]+pd.to_timedelta('193m')\n",
    "            t=(ds[d])\n",
    "        ts.append(t)\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-60-77652dbc15c9>:12: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  szotarHU=df.set_index('HU',drop=False).T.to_dict()\n",
      "<ipython-input-60-77652dbc15c9>:13: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  szotarRO=df.set_index('RO',drop=False).T.to_dict()\n",
      "<ipython-input-60-77652dbc15c9>:14: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  szotarEN=df.set_index('EN',drop=False).T.to_dict()\n"
     ]
    }
   ],
   "source": [
    "szotardf,szotar,szotarHU,szotarRO,szotarEN=get_szotar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import pytz\n",
    "utc=pytz.UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push2influx(df,measurement,field_columns,tag_columns,shift=False,dbclient=client,wo=write_out,fo=full_overwrite,daily=True):\n",
    "    if wo:\n",
    "        df=df.sort_index()\n",
    "        # df.index = utc.localize(df.index) \n",
    "        df.index=df.index.tz_localize('GMT')#.tz_convert('Europe/Bucharest')\n",
    "        if shift:\n",
    "            df.index+=pd.to_timedelta('12h')\n",
    "        if fo: \n",
    "            print('Purging',measurement,'...')\n",
    "            dbclient.query('DROP MEASUREMENT '+measurement)\n",
    "        else:\n",
    "            latest=dbclient.query('SELECT * FROM '+measurement+' GROUP BY \"1d\" ORDER BY DESC LIMIT 1')\n",
    "            if latest:\n",
    "                lat=latest[list(latest.keys())[0]].index[0]\n",
    "                if daily: lat+=pd.to_timedelta('1d')\n",
    "                df=df[lat:]\n",
    "                print('Slicing',measurement,'from',lat,'...')\n",
    "            else:\n",
    "                print('No data in db for',measurement,'...')\n",
    "        time.sleep(3)\n",
    "        print('Writing to',measurement,'...')\n",
    "        bsize=5000\n",
    "        bwait=2\n",
    "        print(len(df),'data points will be written in',len(df)/bsize,'batches.')\n",
    "        print('Expected query running time is:',int((len(df)/bsize)*bwait*1.1)+3,'seconds.')\n",
    "        for i in range(int(len(df)/bsize)+1):\n",
    "            r=range(i*bsize,min(len(df),(i+1)*bsize))\n",
    "            dc=df.iloc[r]\n",
    "            print('Writing batch',i+1,'...')\n",
    "            dbclient.write_points(dc, measurement, protocol=protocol,\n",
    "                                field_columns=field_columns,\n",
    "                                tag_columns=[])\n",
    "            time.sleep(bwait)\n",
    "        time.sleep(3)\n",
    "        print('Done!')\n",
    "    else:\n",
    "        print('Write-out not enabled. Skipping...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DateLaZi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new method from DateLaZi\n",
    "# dlz=requests.get('https://datelazi.ro/latestData.json').content\n",
    "# dlz=requests.get('https://di5ds1eotmbx1.cloudfront.net/latestData.json').content\n",
    "dlz=requests.get('https://d35p9e4fm9h3wo.cloudfront.net/latestData.json').content\n",
    "dlz=json.loads(dlz)\n",
    "dlz['historicalData'][dlz['currentDayStats']['parsedOnString']]=dlz['currentDayStats']\n",
    "dlzs=[]\n",
    "dlz_counties=[]\n",
    "for date in dlz['historicalData']:\n",
    "    d={}\n",
    "    mdate=date.replace('2018-11-07','2020-11-07').replace('2020-01-05','2021-01-05').replace('2020-01-07','2021-01-07')\n",
    "    d['date']=mdate\n",
    "    d['cases']=dlz['historicalData'][date]['numberInfected']\n",
    "    d['heals']=dlz['historicalData'][date]['numberCured']\n",
    "    d['deaths']=dlz['historicalData'][date]['numberDeceased']\n",
    "    if 'vaccines' in dlz['historicalData'][date]:\n",
    "        if dlz['historicalData'][date]['vaccines']:\n",
    "            for v in dlz['historicalData'][date]['vaccines']:\n",
    "                for k in ['total_administered','immunized']:\n",
    "                    k2=k.replace('immunized','total_immunized')\n",
    "                    if k2 not in d: d[k2]=0\n",
    "                    d[k2]+=dlz['historicalData'][date]['vaccines'][v][k]\n",
    "                    d[k2+'_'+v]=dlz['historicalData'][date]['vaccines'][v][k]\n",
    "    if 'countyInfectionsNumbers' in dlz['historicalData'][date]:\n",
    "        counties=dlz['historicalData'][date]['countyInfectionsNumbers']\n",
    "        if counties:\n",
    "            for county in counties:\n",
    "                dummy={'date':mdate,county:dlz['historicalData'][date]['countyInfectionsNumbers'][county]}\n",
    "                if county=='PH':\n",
    "                    if date=='2020-12-01':\n",
    "                        dummy[county]=19395\n",
    "                dlz_counties.append(dummy)\n",
    "    dlzs.append(d)\n",
    "dl=pd.DataFrame(dlzs).set_index('date').sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manual fixes\n",
    "dl.loc['2021-04-08','cases']=993613\n",
    "dl.loc['2021-04-08','heals']=890528\n",
    "dl.loc['2021-04-08','deaths']=24733"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in dl.columns[3:]:\n",
    "    dl[c]=dl[c].cumsum()\n",
    "dl2=dl.diff()\n",
    "dl2.columns=['case','heal','death']+[i.replace('total_','') for i in dl2.columns[3:]]\n",
    "dl['active']=dl['cases']-dl['heals']-dl['deaths']\n",
    "dl=dl.join(dl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-02 2021-05-02\n"
     ]
    }
   ],
   "source": [
    "latest=dl.index[-1]\n",
    "now=str(pd.to_datetime(\"now\"))[:10]\n",
    "print(latest,now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests from `graphs.ro`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-02\n"
     ]
    }
   ],
   "source": [
    "r=requests.get('https://www.graphs.ro/json.php')\n",
    "graphs_ro=json.loads(r.content)['covid_romania']\n",
    "g=pd.DataFrame(graphs_ro)\n",
    "# g['date']=pd.to_datetime(g['reporting_date'])\n",
    "g['date']=g['reporting_date']\n",
    "g=g.set_index('date')\n",
    "g['tests']=g['total_tests']\n",
    "g['test']=g['new_tests_today']\n",
    "latest2=g.index[0]\n",
    "print(latest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-02\n"
     ]
    }
   ],
   "source": [
    "latest=str(min(pd.to_datetime(latest),pd.to_datetime(latest2)))[:10]\n",
    "print(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl=dl.join(g[['tests','test']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Governance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='governance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(url+sheet)\n",
    "# dl=pd.concat([df.set_index('date').sort_index()[:'2020-03-17'][dl.columns[:-1]],\n",
    "#           dl['2020-03-18':]])\n",
    "df=df.set_index('date').sort_index(ascending='True').join(dl,lsuffix='_g')#[20:] #[:-1] vaccines nincs a governance-ban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill from local, if missing in DateLaZi\n",
    "for c in ['active','cases','heals','deaths','case','heal','death']:\n",
    "    df[c]=df[c].fillna(df[c+'_g'].astype(str).str.replace(',','')).replace('nan',np.nan)\n",
    "df=df.dropna(how='all',axis=0).dropna(how='all',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df14=df[['cases']].reset_index().join(df[['cases']][14:].reset_index(),lsuffix='1')\n",
    "df14['case14']=df14['cases'].astype(float)-df14['cases1'].astype(float)\n",
    "df=df.join(df14.set_index('date')['case14'].dropna().astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28351"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index=pd.to_datetime(df.index)\n",
    "df0=df.copy()\n",
    "#df['date']=pd.to_datetime(df['date'])\n",
    "#df=df[df.columns[:13]].set_index('date')\n",
    "vaccine_totals=[i for i in list(dl2.columns[3:])+list(dl.columns[3:len(dl2.columns)]) if 'total_' in i]\n",
    "df=pd.DataFrame(df[['active','cases','heals','deaths','case14']+\\\n",
    "                  vaccine_totals])\n",
    "for c in [i for i in df.columns if '_administered' in i]:\n",
    "    df[c.replace('_administered','_first')]=df[c]-df[c.replace('_administered','_immunized')]           \n",
    "df=df.stack().reset_index().set_index('date')\n",
    "df.columns=['type','value']\n",
    "df['value']=df['value'].astype(str).str.replace(',','').astype(float).astype(int)\n",
    "df=df.join(szotardf,on='type')\n",
    "df=pd.DataFrame(df.reset_index().set_index(['date','type','value']).stack()).reset_index().set_index('date')\n",
    "df.columns=['type','value','lang','langtype']\n",
    "current=int(df[df['type']=='case14']['value'][-1]) #sajat becsles\n",
    "# current=df[df['type']=='active']['value'][-1] #official\n",
    "current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.to_csv('df0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>active</th>\n",
       "      <th>case14</th>\n",
       "      <th>case</th>\n",
       "      <th>heal</th>\n",
       "      <th>death</th>\n",
       "      <th>cases</th>\n",
       "      <th>heals</th>\n",
       "      <th>deaths</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-04-28</th>\n",
       "      <td>40906.0</td>\n",
       "      <td>35330.0</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>3595.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1051779.0</td>\n",
       "      <td>983040.0</td>\n",
       "      <td>27833.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-29</th>\n",
       "      <td>39831.0</td>\n",
       "      <td>33328.0</td>\n",
       "      <td>1850.0</td>\n",
       "      <td>2787.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>1053629.0</td>\n",
       "      <td>985827.0</td>\n",
       "      <td>27971.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-30</th>\n",
       "      <td>37763.0</td>\n",
       "      <td>31700.0</td>\n",
       "      <td>1636.0</td>\n",
       "      <td>3566.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>1055265.0</td>\n",
       "      <td>989393.0</td>\n",
       "      <td>28109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-01</th>\n",
       "      <td>35773.0</td>\n",
       "      <td>29533.0</td>\n",
       "      <td>1307.0</td>\n",
       "      <td>3212.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1056572.0</td>\n",
       "      <td>992605.0</td>\n",
       "      <td>28194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-02</th>\n",
       "      <td>33867.0</td>\n",
       "      <td>28351.0</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>2901.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1057655.0</td>\n",
       "      <td>995506.0</td>\n",
       "      <td>28282.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             active   case14    case    heal  death      cases     heals  \\\n",
       "date                                                                       \n",
       "2021-04-28  40906.0  35330.0  2240.0  3595.0  150.0  1051779.0  983040.0   \n",
       "2021-04-29  39831.0  33328.0  1850.0  2787.0  138.0  1053629.0  985827.0   \n",
       "2021-04-30  37763.0  31700.0  1636.0  3566.0  138.0  1055265.0  989393.0   \n",
       "2021-05-01  35773.0  29533.0  1307.0  3212.0   85.0  1056572.0  992605.0   \n",
       "2021-05-02  33867.0  28351.0  1083.0  2901.0   88.0  1057655.0  995506.0   \n",
       "\n",
       "             deaths  \n",
       "date                 \n",
       "2021-04-28  27833.0  \n",
       "2021-04-29  27971.0  \n",
       "2021-04-30  28109.0  \n",
       "2021-05-01  28194.0  \n",
       "2021-05-02  28282.0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check\n",
    "cols=[ 'active','case14', 'case', 'heal', 'death','cases', 'heals', 'deaths']\n",
    "dx=df0[cols].dropna(how='all')\n",
    "dx=dx.loc[~dx.index.isnull()]\n",
    "dx[cols].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df0[['cases', 'heals', 'deaths', 'total_administered',\n",
    "   'total_administered_pfizer', 'total_immunized',\n",
    "   'total_immunized_pfizer', 'total_administered_moderna',\n",
    "   'total_immunized_moderna', 'total_administered_astra_zeneca',\n",
    "   'total_immunized_astra_zeneca', 'active', 'case', 'heal', 'death',\n",
    "   'administered', 'administered_pfizer', 'immunized', 'immunized_pfizer',\n",
    "   'administered_moderna', 'immunized_moderna',\n",
    "   'administered_astra_zeneca', 'immunized_astra_zeneca', 'tests', 'test',\n",
    "   'case14']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-85-4446d7339660>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[c]=df1[c].astype(str).str.replace(',','').astype(float)\n"
     ]
    }
   ],
   "source": [
    "for c in df1:\n",
    "    df1[c]=df1[c].astype(str).str.replace(',','').astype(float)\n",
    "df1.to_csv('github/data/time_series_ro_daily.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Run till here to test Grafana only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.replace(0,np.nan).dropna()\n",
    "df1=df1[df1['type'].isin(['active', 'cases', 'heals', 'deaths', 'case14'])]\n",
    "df2=df.replace(0,np.nan).dropna()\n",
    "df2=df2[~(df2['type'].isin(['active', 'cases', 'heals', 'deaths', 'case14']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slicing governance1 from 2021-05-03 00:00:00+00:00 ...\n",
      "Writing to governance1 ...\n",
      "0 data points will be written in 0.0 batches.\n",
      "Expected query running time is: 3 seconds.\n",
      "Writing batch 1 ...\n",
      "Done!\n",
      "Slicing vaccine1 from 2021-05-03 00:00:00+00:00 ...\n",
      "Writing to vaccine1 ...\n",
      "0 data points will be written in 0.0 batches.\n",
      "Expected query running time is: 3 seconds.\n",
      "Writing batch 1 ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "field_columns=['value']\n",
    "tag_columns=['type','lang','langtype']\n",
    "measurement='governance1'\n",
    "# push2influx(df1,measurement,field_columns,tag_columns,fo=True)\n",
    "push2influx(df1,measurement,field_columns,tag_columns)\n",
    "measurement='vaccine1'\n",
    "# push2influx(df2,measurement,field_columns,tag_columns,fo=True)\n",
    "push2influx(df2,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_csv(url+sheet)\n",
    "df=df0.copy()\n",
    "\n",
    "# df['date']=pd.to_datetime(df['date'])\n",
    "# df=df[df.columns[:13]].set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daily cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['case/test']=100*df['case'].astype(str).str.replace(',','').astype(float)/\\\n",
    "    df['test'].astype(str).str.replace(',','').astype(float)\n",
    "df['death_rate']=100*df['death'].astype(str).str.replace(',','').astype(float)/\\\n",
    "    df['case'].astype(str).str.replace(',','').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(df[['death','heal','case','case/test','death_rate']].stack()).reset_index().set_index('date')\n",
    "df.columns=['type','value']\n",
    "df['value']=df['value'].astype(str).str.replace(',','').astype(float)\n",
    "df=df.join(szotardf,on='type')\n",
    "df=pd.DataFrame(df.reset_index().set_index(['date','type','value']).stack()).reset_index().set_index('date')\n",
    "df.columns=['type','value','lang','langtype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slicing governance2 from 2021-05-03 00:00:00+00:00 ...\n",
      "Writing to governance2 ...\n",
      "0 data points will be written in 0.0 batches.\n",
      "Expected query running time is: 3 seconds.\n",
      "Writing batch 1 ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "field_columns=['value']\n",
    "tag_columns=['type','lang','langtype']\n",
    "measurement='governance2'\n",
    "# push2influx(df.replace(0,np.nan).dropna(),measurement,field_columns,tag_columns,fo=True)\n",
    "push2influx(df.replace(0,np.nan).dropna(),measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='minidashboard'\n",
    "dm=pd.read_csv(url+sheet)\n",
    "# sheet='governance'\n",
    "# df=pd.read_csv(url+sheet)\n",
    "# df['date']=pd.to_datetime(df['date'])\n",
    "# df=df[df.columns[:10]].set_index('date')\n",
    "# df=df0[list(dl.columns)+['tests','test']].dropna(how='all')\n",
    "df=df0[list(dl.columns)].dropna(how='all')\n",
    "df=df.loc[~df.index.isnull()]\n",
    "for i in dm.set_index('ID')['UI'].iteritems():\n",
    "    df[i[0]]=i[1]\n",
    "sheet='EcMonitor'\n",
    "du=pd.read_csv(url+sheet)\n",
    "du=du.set_index('date').loc['Unemployment ratio'][2:].dropna()\n",
    "du.index=[(pd.to_datetime('now')-pd.to_timedelta('11D')*(1+i)).strftime('%Y-%m-%d') for i in range(len(du))][::-1]\n",
    "du=pd.DataFrame(du)\n",
    "du.columns=['unemployment']\n",
    "du.index=pd.to_datetime(du.index)\n",
    "df=df.join(du)\n",
    "sheet='employmentdata'\n",
    "de=pd.read_csv(url+sheet)\n",
    "de['date']=pd.to_datetime(de['date'])\n",
    "de=de[de.columns[:3]].set_index('date')\n",
    "de.columns=['felbontott','felfuggesztett']\n",
    "# df=df.join(de.ffill())\n",
    "for c in de.columns:\n",
    "    de[c]=de[c].astype(str).str.replace(',','').str.replace('%','').astype(float)#.interpolate(method='linear').dropna()\n",
    "df=df.join(de)\n",
    "df=df.join(mobility_mini)\n",
    "for c in df.columns:\n",
    "    df[c]=df[c].astype(str).str.replace(',','').str.replace('%','').astype(float)\n",
    "sheet='exchangerates'\n",
    "dx=pd.read_csv(url+sheet)\n",
    "dx=dx[['date','EUR - RON (megváltozás)']][5:-1]\n",
    "dx['date']=pd.to_datetime(dx['date'])\n",
    "dx=dx.set_index('date')\n",
    "dx.columns=['xch']\n",
    "dx['xch']=dx['xch'].astype(str).str.replace(',','').str.replace('%','').astype(float).sort_index().cumsum()\n",
    "df=df.join(dx)\n",
    "df['xch']=df['xch'].ffill()\n",
    "sheet='stocks_all'\n",
    "dk=pd.read_csv(url+sheet)[bets].dropna()\n",
    "dk['date']=pd.to_datetime(dk[bets[0]])\n",
    "dk=dk.set_index('date').drop(bets[0],axis=1)\n",
    "dk.columns=['bet']\n",
    "dk=dk.reindex(df.index)\n",
    "dk['bet']=dk['bet'].astype(str).str.replace(',','').str.replace('%','').astype(float).sort_index().cumsum()\n",
    "df=df.join(dk)\n",
    "sheet='MiniGDP'\n",
    "dg=pd.read_csv(url+sheet)\n",
    "dg1=dg[['Date','GDP (QoQ, SA)']].dropna()\n",
    "dg1.index=[(pd.to_datetime('now')-pd.to_timedelta('2D')*(1+i)).strftime('%Y-%m-%d') for i in range(len(dg1))][::-1]\n",
    "dg2=dg[['Date.1','GDP']].dropna()\n",
    "dg2.index=[(pd.to_datetime('now')-pd.to_timedelta('8D')*(1+i)).strftime('%Y-%m-%d') for i in range(len(dg2))][::-1]\n",
    "sheet='DFMChartYoY'\n",
    "dg3=pd.read_csv(url+sheet).T\n",
    "dg3=pd.read_csv(url+sheet,skiprows=19,nrows=2).T.iloc[1:].dropna()[1]\n",
    "dg3.index=[(pd.to_datetime('now')-pd.to_timedelta('1D')*(1+i)).strftime('%Y-%m-%d') for i in range(len(dg3))][::-1]\n",
    "dg=dg1.join(dg2).join(dg3)[['GDP','GDP (QoQ, SA)',1]].astype(float)\n",
    "dg.columns=['gdp','gdpq','employees']\n",
    "dg.index=pd.to_datetime(dg.index)\n",
    "df=df.join(dg)\n",
    "df=df[:pd.to_datetime('now')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slicing governance3 from 2021-05-03 00:00:00+00:00 ...\n",
      "Writing to governance3 ...\n",
      "0 data points will be written in 0.0 batches.\n",
      "Expected query running time is: 3 seconds.\n",
      "Writing batch 1 ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "field_columns=list(df.columns)\n",
    "tag_columns=[]\n",
    "measurement='governance3'\n",
    "# push2influx(df,measurement,field_columns,tag_columns,wo=True,fo=True)\n",
    "push2influx(df,measurement,field_columns,tag_columns,wo=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grafana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('432', 28351, '28&nbsp;351', '02', '01:29')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today0=now[-2:]\n",
    "if today0[0]=='0': \n",
    "    today=today0[1]\n",
    "else:\n",
    "    today=today0\n",
    "currents=str(current)[:-3]+'&nbsp;'+str(current)[-3:]\n",
    "hour=str(pd.to_datetime('now')+pd.to_timedelta('3h'))[11:16]\n",
    "str(szotar['report']['UI'][1:]),current,currents,today0,hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def darken2(color):\n",
    "    return '#'+str(hex(int(\"0x\"+color[1:], 16) & 0xfefefe >> 1))[2:]\n",
    "def brighten2(color):\n",
    "    return '#'+str(hex(int(\"0x\"+color[1:], 16) & 0x7f7f7f << 1))[2:]\n",
    "def adjust_lightness(color, amount=0.5):\n",
    "    import matplotlib.colors as mc\n",
    "    import colorsys\n",
    "    try:\n",
    "        c = mc.cnames[color]\n",
    "    except:\n",
    "        c = color\n",
    "    c = colorsys.rgb_to_hls(*mc.to_rgb(c))\n",
    "    return mc.rgb2hex(colorsys.hls_to_rgb(c[0], max(0, min(1, amount * c[1])), c[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# szotardf,szotar,szotarHU,szotarRO,szotarEN=get_szotar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_to_darken=['#F2CC0C','#CA95E5','#FF780A','#E0B400','#96D98D','#F2495C','#E02F44',\n",
    "                  'lime','#73BF69','#8AB8FF','#3274D9','#D3D3D3','#FF7383','#FADE2A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "top=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iso_counties=pd.read_html('https://en.wikipedia.org/wiki/Counties_of_Romania')[1]\\\n",
    "#     .set_index(['ISO code[note 3]'])['County'].to_dict()\n",
    "# iso_counties['BN']='Bistrița-Năsăud'\n",
    "# iso_counties['CL']='Călărași'\n",
    "# open(htmlipath+'panels/iso_counties.json','w').write(json.dumps(iso_counties))\n",
    "iso_counties=json.loads(open(htmlipath+'panels/iso_counties.json','r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "georo=json.loads(open(htmlipath+'panels/romania-counties.json','r').read())\n",
    "georoco={i['properties']['NAME_1']:i['properties']['ID_1'] for i in georo['objects']['ROU_adm1']['geometries']}   \n",
    "georoco['București']=georoco['Bucharest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='industry_county'\n",
    "df=pd.read_csv(url+sheet)[:-2]\n",
    "df=df[df.columns[:5]]\n",
    "df.columns=['HU','RO','EN','q2','q3']\n",
    "for q in ['q2','q3']:\n",
    "    df[q]=df[q].str.replace('%','').astype(float)\n",
    "df=df.set_index('RO').join(pd.DataFrame(georoco,index=['county']).T).reset_index().dropna()\n",
    "df.columns=['RO','HU','EN','q2','q3','county']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-104-1a3a71a98fd4>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ddd[c+'_high']=True\n",
      "<ipython-input-104-1a3a71a98fd4>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ddd[c+'_high']=False\n"
     ]
    }
   ],
   "source": [
    "for lang in languages:\n",
    "    dc=df[[lang,'q2','q3','county']]\n",
    "    dc.columns=['county','q2','q3','id']\n",
    "    for c in ['q2','q3']:\n",
    "        dd=dc.set_index([c])[['county']].sort_index(ascending=False)\n",
    "        dds=[]\n",
    "        ddd=dd.iloc[:top]\n",
    "        ddd[c+'_high']=True\n",
    "        dds.append(ddd)\n",
    "        ddd=dd.iloc[-top:]\n",
    "        ddd[c+'_high']=False\n",
    "        dds.append(ddd)\n",
    "        dds=pd.concat(dds)\n",
    "        dds[c+'_display']=True\n",
    "        dc=dc.set_index(['county']).join(dds.reset_index().set_index(['county'])\\\n",
    "                                         [[c+'_display',c+'_high']]).reset_index()\n",
    "        dc[c+'_display']=dc[c+'_display'].fillna(False)\n",
    "        \n",
    "    dcqs=[]\n",
    "    for c in ['q2','q3']:\n",
    "        dcq=dc.set_index([c,'county'])[[c+'_display',c+'_high']]\n",
    "        dcq.index.names=['value','county']\n",
    "        dcq['quarter']=c\n",
    "        dcq=dcq.reset_index().set_index(['quarter','county','value'])\n",
    "        dcq.columns=['display','high']\n",
    "        dcq['high']=dcq['high'].fillna(False)\n",
    "        dcqs.append(dcq)\n",
    "    dcqs=pd.concat(dcqs)\n",
    "    dcc=dc.set_index(['county','id'])[['q2','q3']].stack().reset_index()\n",
    "    dcc.columns=['county','id','quarter','value']\n",
    "    dcc=dcc.set_index(['quarter','county','value']).join(dcqs).reset_index()\n",
    "    dcc['q']=dcc['quarter'].replace({'q2':'Q2 vs Q1','q3':'Q3 vs Q2'})\n",
    "    dcc['q0']=dcc['quarter'].replace({'q2':2019,'q3':2020})\n",
    "    # dcc=dcc.sort_values('quarter',ascending=False)\n",
    "    open(htmlipath+'panels/county_'+lang+'.json','w').write(json.dumps(list(dcc.T.to_dict().values())))\n",
    "    # open('county_'+lang+'.json','w').write(json.dumps(list(dc.T.to_dict().values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case county map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='counties_current'\n",
    "dg=pd.read_csv(url+sheet, header=None)\n",
    "dgl=dg[[1,4]].set_index(4).T.to_dict()\n",
    "dgl['Dambovita']=dgl['Dâmbovita']\n",
    "dgl['Szucsáva']=dgl['Suceava']\n",
    "dgl['Galac']=dgl['Galati']\n",
    "dgl['Valcea']=dgl['Vâlcea']\n",
    "dfl=df[languages+['county']].set_index('HU')\n",
    "dh=dfl.join(pd.DataFrame(dgl).T).reset_index().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in languages:\n",
    "    dc=dh[[lang,1,'county']]\n",
    "    dc.columns=['county','value','id']\n",
    "    open(htmlipath+'panels/county2_'+lang+'.json','w').write(json.dumps(list(dc.T.to_dict().values())))\n",
    "    # open('county2_'+lang+'.json','w').write(json.dumps(list(dc.T.to_dict().values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case county map fancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop=json.loads(open(htmlipath+'panels/pop.json').read())\n",
    "pop={i:pop[i][1] for i in pop}\n",
    "pdf=pd.DataFrame(pop,index=['pop']).T\n",
    "pdf.index.name='iso'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "dq=pd.DataFrame(dlz_counties).groupby('date').mean().drop('-',axis=1).stack().reset_index()\n",
    "dq.columns=['date','iso','cases']\n",
    "iso2=pd.DataFrame(iso_counties,index=['EN']).T.reset_index()\n",
    "iso2.columns=['iso','EN']\n",
    "dq=dq.set_index('iso').join(pdf).join(iso2.set_index('iso')).set_index('EN').join(dh.set_index('EN').drop(1,axis=1)).reset_index()\n",
    "dq['case_cap']=dq['cases']*1000/dq['pop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-109-0c1092ac59e8>:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d['county']='d'\n",
      "<ipython-input-109-0c1092ac59e8>:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d['case_14_cap']=4\n",
      "<ipython-input-109-0c1092ac59e8>:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d['id']=99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-109-0c1092ac59e8>:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d['county']='d'\n",
      "<ipython-input-109-0c1092ac59e8>:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d['case_14_cap']=4\n",
      "<ipython-input-109-0c1092ac59e8>:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d['id']=99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-109-0c1092ac59e8>:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d['county']='d'\n",
      "<ipython-input-109-0c1092ac59e8>:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d['case_14_cap']=4\n",
      "<ipython-input-109-0c1092ac59e8>:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d['id']=99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN\n"
     ]
    }
   ],
   "source": [
    "dmss=[]\n",
    "for lang in languages:\n",
    "    dms=[]\n",
    "    # dm=dq.set_index([lang,'date'])[['cases','case_cap','pop','county']]\n",
    "    dm=dq.set_index('EN').join(iso2.set_index('EN')).reset_index().set_index([lang,'date'])[['cases','case_cap','pop','county','iso']]\n",
    "    for m in dm.index.get_level_values(0).unique():\n",
    "        dc=dm.loc[m].sort_index()\n",
    "        p=dc.iloc[0]['pop']\n",
    "        dc['case_14']=dc['cases'].diff().rolling(14).sum()\n",
    "        dc['case_14_cap']=dc['case_14']*1000/p\n",
    "        dc['id']=dc['county']\n",
    "        dc['county']=m\n",
    "        dms.append(dc.dropna())\n",
    "    dms=pd.concat(dms)\n",
    "    dms=dms[((dms['case_14_cap']<14)&(dms['case_14_cap']>0))] #filter out non-sense values\n",
    "    open(htmlipath+'panels/county2c_'+lang+'.json','w').write(json.dumps(list(dms.reset_index().T.to_dict().values())))\n",
    "    dms2=dms.sort_index()['2020-08-05':]\n",
    "    open(htmlipath+'panels/county2d_'+lang+'.json','w').write(json.dumps(list(dms2.reset_index().T.to_dict().values())))\n",
    "    \n",
    "    dc=dms.reset_index().sort_index(ascending=False)\n",
    "    for c in ['cases','case_cap','case_14','case_14_cap']:\n",
    "        dd=dc.reset_index().set_index(['date',c])[['county']].sort_index(ascending=False)\n",
    "        dds=[]\n",
    "        for d in dd.index.get_level_values(0).unique():\n",
    "            dds.append(dd.loc[[d]].iloc[:top])\n",
    "            dds.append(dd.loc[[d]].iloc[-top:])\n",
    "        dds=pd.concat(dds)\n",
    "        dds[c+'_display']=True\n",
    "        dc=dc.set_index(['date','county']).join(dds.reset_index().set_index(['date','county'])[c+'_display']).reset_index()\n",
    "        dc[c+'_display']=dc[c+'_display'].fillna(False)\n",
    "        \n",
    "    d=dc.iloc[[0]]\n",
    "    d['county']='d'\n",
    "    d['case_14_cap']=4\n",
    "    d['id']=99\n",
    "        \n",
    "    open(htmlipath+'panels/county2b_'+lang+'.json','w').write(json.dumps(list(d.T.to_dict().values())+list(dc.T.to_dict().values())))\n",
    "    open(htmlipath+'panels/daily/county2b_'+latest+'_'+lang+'.json','w').write(json.dumps(list(d.T.to_dict().values())+list(dc.T.to_dict().values())))\n",
    "    dms['lang']=lang\n",
    "    dmss.append(dms)\n",
    "    print(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmss[1].to_csv('github/data/time_series_ro_counties_daily.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18156"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_counties2=open(htmlipath+'panels/cases_counties2.html','r').read()\n",
    "cases_counties2=cases_counties2[:cases_counties2.find('daily/county2b_\\' + \\'2021-')+20]+latest+cases_counties2[cases_counties2.find('daily/county2b_\\' + \\'2021-')+30:]\n",
    "open(htmlipath+'panels/cases_counties2.html','w').write(cases_counties2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counties per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "dz=dh.set_index('EN').join(pd.DataFrame(pd.DataFrame(iso_counties,index=['county'])\\\n",
    "                                     .T.reset_index().set_index('county'))).reset_index()\n",
    "dlz_data=pd.DataFrame(pd.DataFrame(dlz_counties).groupby('date').mean().stack()).reset_index()\n",
    "dlz_data.columns=['date','index','value']\n",
    "dz=dlz_data.set_index('index').join(dz.set_index('index')).dropna().set_index('date')\n",
    "dz.index=pd.to_datetime(dz.index)\n",
    "dz2=dz.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dz2=dz2.ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "dz=pd.DataFrame(dz.set_index(['county','value',1],append=True).stack()).reset_index()\n",
    "dz.columns=['date','county','value','dump','lang','langtype']\n",
    "dz=dz.set_index('date').drop('dump',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slicing counties from 2021-05-02 00:00:00+00:00 ...\n",
      "Writing to counties ...\n",
      "126 data points will be written in 0.0252 batches.\n",
      "Expected query running time is: 3 seconds.\n",
      "Writing batch 1 ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "field_columns=['value']\n",
    "tag_columns=['lang','langtype']\n",
    "measurement='counties'\n",
    "push2influx(dz,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counties active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "dz2=dz2.reset_index().set_index(['EN','HU','RO','county',1,'date'])\\\n",
    "    .unstack().diff(axis=1).stack().reset_index().set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "dz2=pd.DataFrame(dz2.set_index(['county','value',1],append=True).stack()).reset_index()\n",
    "dz2.columns=['date','county','value','dump','lang','langtype']\n",
    "dz2=dz2.set_index('date').drop('dump',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slicing counties2 from 2021-05-02 00:00:00+00:00 ...\n",
      "Writing to counties2 ...\n",
      "126 data points will be written in 0.0252 batches.\n",
      "Expected query running time is: 3 seconds.\n",
      "Writing batch 1 ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "field_columns=['value']\n",
    "tag_columns=['lang','langtype']\n",
    "measurement='counties2'\n",
    "push2influx(dz2,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "County intensity map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmsr=pd.concat(dmss)[['case_14_cap','county','iso','lang']]\n",
    "dmsr.index=pd.to_datetime(dmsr.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slicing counties3 from 2021-05-02 00:00:00+00:00 ...\n",
      "Writing to counties3 ...\n",
      "126 data points will be written in 0.0252 batches.\n",
      "Expected query running time is: 3 seconds.\n",
      "Writing batch 1 ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "field_columns=['case_14_cap']\n",
    "tag_columns=['county','iso','lang']\n",
    "measurement='counties3'\n",
    "push2influx(dmsr,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Push to Grafana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]> b'{\"id\":2,\"slug\":\"magyar\",\"status\":\"success\",\"uid\":\"hu\",\"url\":\"/d/hu/magyar\",\"version\":362}'\n",
      "<Response [200]> b'{\"id\":5,\"slug\":\"magyar-light\",\"status\":\"success\",\"uid\":\"hu-light\",\"url\":\"/d/hu-light/magyar-light\",\"version\":178}'\n",
      "<Response [200]> b'{\"id\":3,\"slug\":\"romana\",\"status\":\"success\",\"uid\":\"ro\",\"url\":\"/d/ro/romana\",\"version\":265}'\n",
      "<Response [200]> b'{\"id\":6,\"slug\":\"romana-light\",\"status\":\"success\",\"uid\":\"ro-light\",\"url\":\"/d/ro-light/romana-light\",\"version\":170}'\n",
      "<Response [200]> b'{\"id\":4,\"slug\":\"english\",\"status\":\"success\",\"uid\":\"en\",\"url\":\"/d/en/english\",\"version\":226}'\n",
      "<Response [200]> b'{\"id\":7,\"slug\":\"english-light\",\"status\":\"success\",\"uid\":\"en-light\",\"url\":\"/d/en-light/english-light\",\"version\":171}'\n"
     ]
    }
   ],
   "source": [
    "nevuto={'0':'á','1':'é','3':'á','2':'á','4':'é','5':'é','6':'á','7':'é','8':'á','9':'é'}\n",
    "for lang in languages:\n",
    "    response = requests.get(grafana+'api/dashboards/uid/'+lang.lower(), headers=headers)\n",
    "    model=json.loads(response.content)['dashboard']\n",
    "    for i in model['panels']:\n",
    "        if lang=='HU':\n",
    "            #print(i['id'],i['type'],i['title'])\n",
    "            if i['id']==82:\n",
    "                i['content']=i['content'][:i['content'].find('<b>')+3]+str(szotar['report']['UI'][1:])+\\\n",
    "                    i['content'][i['content'].find('</b>'):i['content'].rfind('<b>')+3]+currents+\\\n",
    "                    i['content'][i['content'].rfind('</b>'):]\n",
    "            if i['id']==93:\n",
    "                i['content']=i['content'][:i['content'].rfind('</b>')-2]+today0+\\\n",
    "                i['content'][i['content'].rfind('</b>'):]\n",
    "        elif lang=='EN':\n",
    "            if i['id']==82:\n",
    "                i['content']=i['content'][:i['content'].find('<b>')+3]+str(szotar['report']['UI'][1:])+\\\n",
    "                    i['content'][i['content'].find('</b>'):i['content'].rfind('<b>')+3]+currents+\\\n",
    "                    i['content'][i['content'].rfind('</b>'):]\n",
    "            if i['id']==93:\n",
    "                i['content']=i['content'][:i['content'].rfind('</b>')-2]+today0+\\\n",
    "                i['content'][i['content'].rfind('</b>'):]\n",
    "        elif lang=='RO':\n",
    "            if i['id']==82:\n",
    "                i['content']=i['content'][:i['content'].find('<b>')+3]+str(szotar['report']['UI'][1:])+\\\n",
    "                    i['content'][i['content'].find('</b>'):i['content'].rfind('<b>')+3]+currents+\\\n",
    "                    i['content'][i['content'].rfind('</b>'):]\n",
    "            if i['id']==93:\n",
    "                i['content']=i['content'][:i['content'].rfind('<b>')+3]+today0+\\\n",
    "                i['content'][i['content'].rfind('<b>')+5:]\n",
    "            \n",
    "    r=requests.post(grafana+'api/dashboards/db', headers=headers, json={\"dashboard\":model,\n",
    "                                                                            \"folderId\": folder_id,\n",
    "                                                                            \"overwrite\": True\n",
    "                                                                           })       \n",
    "    print(r,r.content)\n",
    "    open(lang+'.json','w').write(json.dumps(model))    \n",
    "    \n",
    "    model_light=json.dumps(model).replace('dark','light',9999).replace('lightGray','#52545C',9999)\\\n",
    "        .replace('#d3d3d3','#52545c',9999)\\\n",
    "        .replace('csaladen.es/favicon.ico\" style=\"','csaladen.es/favicon.ico\" style=\"filter: brightness(0.3);',9999)\n",
    "    for color in colors_to_darken:\n",
    "        model_light=model_light.replace(color,adjust_lightness(color,0.8),9999)\n",
    "        model_light=model_light.replace(color.lower(),adjust_lightness(color,0.8),9999)\n",
    "    model=json.loads(model_light)\n",
    "    model['title']=titles[lang]+' Light'\n",
    "    model['uid']=uids_light[lang]\n",
    "    model['id']=iids_light[lang]\n",
    "    r=requests.post(grafana+'api/dashboards/db', headers=headers, json={\"dashboard\":model,\n",
    "                                                                            \"folderId\": folder_id,\n",
    "                                                                            \"overwrite\": True\n",
    "                                                                           })    \n",
    "    print(r,r.content)\n",
    "    open(lang+'-light.json','w').write(json.dumps(model))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vaccines per age group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datagov1a=pd.read_excel('https://data.gov.ro/dataset/b86a78a3-7f88-4b53-a94f-015082592466/resource/bc19c354-644d-4a24-a26f-512129dbc70d/download/transparenta_vaccinare_martie_2021.xlsx')\n",
    "# datagov1b=pd.read_excel('https://data.gov.ro/dataset/b86a78a3-7f88-4b53-a94f-015082592466/resource/a0eb9ff2-9b97-430c-b285-360cadb55307/download/vaccinare-covid19-grupe-risc-01-01.04.2021.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure remote git for `denesdata/roeim/data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git config core.sparseCheckout true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/github\n"
     ]
    }
   ],
   "source": [
    "# !mkdir github\n",
    "%cd /home/jovyan/work/github\n",
    "# !git init\n",
    "# !git remote add -f origin https://github.com/denesdata/roeim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git config core.sparseCheckout true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !echo \"data\" >> .git/info/sparse-checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git pull origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Might have to go out to Terminal\n",
    "#Cache GitHub credentials for one month #3600*24*30\n",
    "# !git config --global credential.helper \"cache --timeout=2592000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 50f9d5b] automated data update 2021-05-02\n",
      " 3 files changed, 4177 insertions(+), 3188 deletions(-)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/denesdata/roeim\n",
      "   5677c09..50f9d5b  master -> master\n"
     ]
    }
   ],
   "source": [
    "%%script env my_bash_variable=\"$latest2\" bash\n",
    "git add --all\n",
    "git commit --all -m \"automated data update $my_bash_variable\"\n",
    "git push origin master"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
