{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from influxdb import DataFrameClient\n",
    "import json\n",
    "# import feedparser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "purge=False\n",
    "# purge=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_annoations=False\n",
    "# process_annoations=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_macro=False\n",
    "process_macro=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_out=False\n",
    "write_out=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_overwrite=False\n",
    "# full_overwrite=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pre-params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0=pd.read_csv('df0.csv').set_index('date')\n",
    "df0.index=pd.to_datetime(df0.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "bets=json.loads(open('bets.json','r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity=pd.read_csv('severity.csv').set_index('date')\n",
    "severity.index=pd.to_datetime(severity.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobility=pd.read_csv('mobility.csv').set_index('date')\n",
    "mobility.index=pd.to_datetime(mobility.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobility_mini=pd.read_csv('mobility_mini.csv').set_index('date')\n",
    "mobility_mini.index=pd.to_datetime(mobility_mini.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish DB connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'admin'\n",
    "password = open('auth/influxa.txt','r').read()\n",
    "host='influxdb'\n",
    "port=8086\n",
    "dbname='base'\n",
    "dbname_long='long'\n",
    "protocol = 'line' #'json'\n",
    "client = DataFrameClient(host, port, user, password, dbname)\n",
    "client_long = DataFrameClient(host, port, user, password, dbname_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "if purge:\n",
    "    client.drop_database(dbname)\n",
    "    client.drop_retention_policy(dbname)\n",
    "    client.create_database(dbname)\n",
    "    client.create_retention_policy(dbname, '600d', 1, default=True)\n",
    "    client_long.drop_database(dbname_long)\n",
    "    client_long.drop_retention_policy(dbname_long)\n",
    "    client_long.create_database(dbname_long)\n",
    "    client_long.create_retention_policy(dbname_long, '6000d', 1, default=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "htmlipath='../html/'\n",
    "htmlepath='//myserv-html.er/'\n",
    "htmlepath_other='//mybackupserv-html.er/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles={'HU':\"Magyar\",'RO':'Română','EN':'English'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtitles={titles[t]:t for t in titles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "grafana = \"http://grafana:3000/\"\n",
    "headers = {\n",
    "    'Authorization': 'Bearer '+open('auth/grafana.txt','r').read(),\n",
    "    'Accept': 'application/json',\n",
    "    'Content-Type': 'application/json'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(grafana+'api/folders', headers=headers)\n",
    "folders=json.loads(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_id=[f['id'] for f in folders if f['title']=='My Grafana Folder'][0] #General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(grafana+'api/search?folderIds='+str(folder_id), headers=headers)\n",
    "dashs=json.loads(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "uids={rtitles[d['title']]:d['uid'] for d in dashs if d['title'] in rtitles}\n",
    "iids={rtitles[d['title']]:d['id'] for d in dashs if d['title'] in rtitles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "uids_light={rtitles[d['title'].split(' Light')[0]]:d['uid'] for d in dashs if 'Light' in d['title']}\n",
    "iids_light={rtitles[d['title'].split(' Light')[0]]:d['id'] for d in dashs if 'Light' in d['title']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages=['HU','RO','EN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://docs.google.com/spreadsheets/d/'+open('auth/sheet.txt','r').read()+'/gviz/tq?tqx=out:csv&sheet='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_szotar():\n",
    "    sheet='szotar'\n",
    "    columns=languages+[i+'_description' for i in languages]+[i+'_source' for i in languages]\n",
    "    df=pd.read_csv(url+sheet)\n",
    "    df=df[['ID','UI']+columns]\n",
    "    sheet='minidashboard'\n",
    "    df2=pd.read_csv(url+sheet)\n",
    "    df2=df2[['ID','UI']+columns]\n",
    "    df=pd.concat([df,df2])\n",
    "    szotardf=df.set_index('ID')[columns]\n",
    "    szotar=df.set_index('ID').T.to_dict()\n",
    "    szotarHU=df.set_index('HU',drop=False).T.to_dict()\n",
    "    szotarRO=df.set_index('RO',drop=False).T.to_dict()\n",
    "    szotarEN=df.set_index('EN',drop=False).T.to_dict()\n",
    "    return szotardf,szotar,szotarHU,szotarRO,szotarEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_time_conflicts(series):\n",
    "    ds={}\n",
    "    ts=[]\n",
    "    for d in series:\n",
    "        if d not in ds:\n",
    "            ds[d]=pd.to_datetime(d)\n",
    "            t=(ds[d])\n",
    "        else:\n",
    "            ds[d]=ds[d]+pd.to_timedelta('193m')\n",
    "            t=(ds[d])\n",
    "        ts.append(t)\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-157-77652dbc15c9>:12: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  szotarHU=df.set_index('HU',drop=False).T.to_dict()\n",
      "<ipython-input-157-77652dbc15c9>:13: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  szotarRO=df.set_index('RO',drop=False).T.to_dict()\n",
      "<ipython-input-157-77652dbc15c9>:14: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  szotarEN=df.set_index('EN',drop=False).T.to_dict()\n"
     ]
    }
   ],
   "source": [
    "szotardf,szotar,szotarHU,szotarRO,szotarEN=get_szotar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import pytz\n",
    "utc=pytz.UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push2influx(df,measurement,field_columns,tag_columns,shift=False,dbclient=client,wo=write_out,fo=full_overwrite,daily=True):\n",
    "    if wo:\n",
    "        df=df.sort_index()\n",
    "        # df.index = utc.localize(df.index) \n",
    "        df.index=df.index.tz_localize('GMT')#.tz_convert('Europe/Bucharest')\n",
    "        if shift:\n",
    "            df.index+=pd.to_timedelta('12h')\n",
    "        if fo: \n",
    "            print('Purging',measurement,'...')\n",
    "            dbclient.query('DROP MEASUREMENT '+measurement)\n",
    "        else:\n",
    "            latest=dbclient.query('SELECT * FROM '+measurement+' GROUP BY \"1d\" ORDER BY DESC LIMIT 1')\n",
    "            if latest:\n",
    "                lat=latest[list(latest.keys())[0]].index[0]\n",
    "                if daily: lat+=pd.to_timedelta('1d')\n",
    "                df=df[lat:]\n",
    "                print('Slicing',measurement,'from',lat,'...')\n",
    "            else:\n",
    "                print('No data in db for',measurement,'...')\n",
    "        time.sleep(3)\n",
    "        print('Writing to',measurement,'...')\n",
    "        bsize=5000\n",
    "        bwait=2\n",
    "        print(len(df),'data points will be written in',len(df)/bsize,'batches.')\n",
    "        print('Expected query running time is:',int((len(df)/bsize)*bwait*1.1)+3,'seconds.')\n",
    "        for i in range(int(len(df)/bsize)+1):\n",
    "            r=range(i*bsize,min(len(df),(i+1)*bsize))\n",
    "            dc=df.iloc[r]\n",
    "            print('Writing batch',i+1,'...')\n",
    "            dbclient.write_points(dc, measurement, protocol=protocol,\n",
    "                                field_columns=field_columns,\n",
    "                                tag_columns=[])\n",
    "            time.sleep(bwait)\n",
    "        time.sleep(3)\n",
    "        print('Done!')\n",
    "    else:\n",
    "        print('Write-out not enabled. Skipping...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DateLaZi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new method from DateLaZi\n",
    "dlz=requests.get('https://datelazi.ro/latestData.json').content\n",
    "dlz=json.loads(dlz)\n",
    "dlz['historicalData'][dlz['currentDayStats']['parsedOnString']]=dlz['currentDayStats']\n",
    "dlzs=[]\n",
    "dlz_counties=[]\n",
    "for date in dlz['historicalData']:\n",
    "    d={}\n",
    "    mdate=date.replace('2018-11-07','2020-11-07').replace('2020-01-05','2021-01-05').replace('2020-01-07','2021-01-07')\n",
    "    d['date']=mdate\n",
    "    d['cases']=dlz['historicalData'][date]['numberInfected']\n",
    "    d['heals']=dlz['historicalData'][date]['numberCured']\n",
    "    d['deaths']=dlz['historicalData'][date]['numberDeceased']\n",
    "    if 'vaccines' in dlz['historicalData'][date]:\n",
    "        if dlz['historicalData'][date]['vaccines']:\n",
    "            for v in dlz['historicalData'][date]['vaccines']:\n",
    "                for k in ['total_administered','immunized']:\n",
    "                    k2=k.replace('immunized','total_immunized')\n",
    "                    if k2 not in d: d[k2]=0\n",
    "                    d[k2]+=dlz['historicalData'][date]['vaccines'][v][k]\n",
    "                    d[k2+'_'+v]=dlz['historicalData'][date]['vaccines'][v][k]\n",
    "    if 'countyInfectionsNumbers' in dlz['historicalData'][date]:\n",
    "        counties=dlz['historicalData'][date]['countyInfectionsNumbers']\n",
    "        if counties:\n",
    "            for county in counties:\n",
    "                dummy={'date':mdate,county:dlz['historicalData'][date]['countyInfectionsNumbers'][county]}\n",
    "                if county=='PH':\n",
    "                    if date=='2020-12-01':\n",
    "                        dummy[county]=19395\n",
    "                dlz_counties.append(dummy)\n",
    "    dlzs.append(d)\n",
    "dl=pd.DataFrame(dlzs).set_index('date').sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manual fixes\n",
    "dl.loc['2021-04-08','cases']=993613\n",
    "dl.loc['2021-04-08','heals']=890528\n",
    "dl.loc['2021-04-08','deaths']=24733"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in dl.columns[3:]:\n",
    "    dl[c]=dl[c].cumsum()\n",
    "dl2=dl.diff()\n",
    "dl2.columns=['case','heal','death']+[i.replace('total_','') for i in dl2.columns[3:]]\n",
    "dl['active']=dl['cases']-dl['heals']-dl['deaths']\n",
    "dl=dl.join(dl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-08 2021-04-09\n"
     ]
    }
   ],
   "source": [
    "latest=dl.index[-1]\n",
    "now=str(pd.to_datetime(\"now\"))[:10]\n",
    "print(latest,now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests from `graphs.ro`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-08\n"
     ]
    }
   ],
   "source": [
    "r=requests.get('https://www.graphs.ro/json.php')\n",
    "graphs_ro=json.loads(r.content)['covid_romania']\n",
    "g=pd.DataFrame(graphs_ro)\n",
    "# g['date']=pd.to_datetime(g['reporting_date'])\n",
    "g['date']=g['reporting_date']\n",
    "g=g.set_index('date')\n",
    "g['tests']=g['total_tests']\n",
    "g['test']=g['new_tests_today']\n",
    "latest2=g.index[0]\n",
    "print(latest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-08\n"
     ]
    }
   ],
   "source": [
    "latest=str(min(pd.to_datetime(latest),pd.to_datetime(latest2)))[:10]\n",
    "print(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl=dl.join(g[['tests','test']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Governance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='governance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(url+sheet)\n",
    "# dl=pd.concat([df.set_index('date').sort_index()[:'2020-03-17'][dl.columns[:-1]],\n",
    "#           dl['2020-03-18':]])\n",
    "df=df.set_index('date').sort_index(ascending='True').join(dl,lsuffix='_g')#[20:] #[:-1] vaccines nincs a governance-ban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill from local, if missing in DateLaZi\n",
    "for c in ['active','cases','heals','deaths','case','heal','death']:\n",
    "    df[c]=df[c].fillna(df[c+'_g'].astype(str).str.replace(',','')).replace('nan',np.nan)\n",
    "df=df.dropna(how='all',axis=0).dropna(how='all',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "df14=df[['cases']].reset_index().join(df[['cases']][14:].reset_index(),lsuffix='1')\n",
    "df14['case14']=df14['cases'].astype(float)-df14['cases1'].astype(float)\n",
    "df=df.join(df14.set_index('date')['case14'].dropna().astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73819"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index=pd.to_datetime(df.index)\n",
    "df0=df.copy()\n",
    "#df['date']=pd.to_datetime(df['date'])\n",
    "#df=df[df.columns[:13]].set_index('date')\n",
    "vaccine_totals=[i for i in list(dl2.columns[3:])+list(dl.columns[3:len(dl2.columns)]) if 'total_' in i]\n",
    "df=pd.DataFrame(df[['active','cases','heals','deaths','case14']+\\\n",
    "                  vaccine_totals].stack()).reset_index().set_index('date')\n",
    "df.columns=['type','value']\n",
    "df['value']=df['value'].astype(str).str.replace(',','').astype(float).astype(int)\n",
    "df=df.join(szotardf,on='type')\n",
    "df=pd.DataFrame(df.reset_index().set_index(['date','type','value']).stack()).reset_index().set_index('date')\n",
    "df.columns=['type','value','lang','langtype']\n",
    "current=df[df['type']=='case14']['value'][-1] #sajat becsles\n",
    "# current=df[df['type']=='active']['value'][-1] #official\n",
    "current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.to_csv('df0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>active</th>\n",
       "      <th>case14</th>\n",
       "      <th>case</th>\n",
       "      <th>heal</th>\n",
       "      <th>death</th>\n",
       "      <th>cases</th>\n",
       "      <th>heals</th>\n",
       "      <th>deaths</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-04-04</th>\n",
       "      <td>78355.0</td>\n",
       "      <td>77260.0</td>\n",
       "      <td>4151.0</td>\n",
       "      <td>4287.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>974375.0</td>\n",
       "      <td>871950.0</td>\n",
       "      <td>24070.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-05</th>\n",
       "      <td>78309.0</td>\n",
       "      <td>77128.0</td>\n",
       "      <td>3611.0</td>\n",
       "      <td>3537.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>977986.0</td>\n",
       "      <td>875487.0</td>\n",
       "      <td>24190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-06</th>\n",
       "      <td>78402.0</td>\n",
       "      <td>76210.0</td>\n",
       "      <td>5231.0</td>\n",
       "      <td>4942.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>983217.0</td>\n",
       "      <td>880429.0</td>\n",
       "      <td>24386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-07</th>\n",
       "      <td>78353.0</td>\n",
       "      <td>75481.0</td>\n",
       "      <td>5407.0</td>\n",
       "      <td>5281.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>988624.0</td>\n",
       "      <td>885710.0</td>\n",
       "      <td>24561.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-08</th>\n",
       "      <td>78352.0</td>\n",
       "      <td>73819.0</td>\n",
       "      <td>4989.0</td>\n",
       "      <td>4818.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>993613.0</td>\n",
       "      <td>890528.0</td>\n",
       "      <td>24733.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             active   case14    case    heal  death     cases     heals  \\\n",
       "date                                                                      \n",
       "2021-04-04  78355.0  77260.0  4151.0  4287.0   97.0  974375.0  871950.0   \n",
       "2021-04-05  78309.0  77128.0  3611.0  3537.0  120.0  977986.0  875487.0   \n",
       "2021-04-06  78402.0  76210.0  5231.0  4942.0  196.0  983217.0  880429.0   \n",
       "2021-04-07  78353.0  75481.0  5407.0  5281.0  175.0  988624.0  885710.0   \n",
       "2021-04-08  78352.0  73819.0  4989.0  4818.0  172.0  993613.0  890528.0   \n",
       "\n",
       "             deaths  \n",
       "date                 \n",
       "2021-04-04  24070.0  \n",
       "2021-04-05  24190.0  \n",
       "2021-04-06  24386.0  \n",
       "2021-04-07  24561.0  \n",
       "2021-04-08  24733.0  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check\n",
    "cols=[ 'active','case14', 'case', 'heal', 'death','cases', 'heals', 'deaths']\n",
    "dx=df0[cols].dropna(how='all')\n",
    "dx=dx.loc[~dx.index.isnull()]\n",
    "dx[cols].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Run till here to test Grafana only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.replace(0,np.nan).dropna()\n",
    "df1=df1[df1['type'].isin(['active', 'cases', 'heals', 'deaths', 'case14'])]\n",
    "df2=df.replace(0,np.nan).dropna()\n",
    "df2=df2[~(df2['type'].isin(['active', 'cases', 'heals', 'deaths', 'case14']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slicing governance1 from 2021-04-09 00:00:00+00:00 ...\n",
      "Writing to governance1 ...\n",
      "0 data points will be written in 0.0 batches.\n",
      "Expected query running time is: 3 seconds.\n",
      "Writing batch 1 ...\n",
      "Done!\n",
      "Slicing vaccine1 from 2021-04-09 00:00:00+00:00 ...\n",
      "Writing to vaccine1 ...\n",
      "0 data points will be written in 0.0 batches.\n",
      "Expected query running time is: 3 seconds.\n",
      "Writing batch 1 ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "field_columns=['value']\n",
    "tag_columns=['type','lang','langtype']\n",
    "measurement='governance1'\n",
    "# push2influx(df1,measurement,field_columns,tag_columns,fo=True)\n",
    "push2influx(df1,measurement,field_columns,tag_columns)\n",
    "measurement='vaccine1'\n",
    "# push2influx(df2,measurement,field_columns,tag_columns,fo=True)\n",
    "push2influx(df2,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_csv(url+sheet)\n",
    "df=df0.copy()\n",
    "\n",
    "# df['date']=pd.to_datetime(df['date'])\n",
    "# df=df[df.columns[:13]].set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daily cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['case/test']=100*df['case'].astype(str).str.replace(',','').astype(float)/\\\n",
    "    df['test'].astype(str).str.replace(',','').astype(float)\n",
    "df['death_rate']=100*df['death'].astype(str).str.replace(',','').astype(float)/\\\n",
    "    df['case'].astype(str).str.replace(',','').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(df[['death','heal','case','case/test','death_rate']].stack()).reset_index().set_index('date')\n",
    "df.columns=['type','value']\n",
    "df['value']=df['value'].astype(str).str.replace(',','').astype(float)\n",
    "df=df.join(szotardf,on='type')\n",
    "df=pd.DataFrame(df.reset_index().set_index(['date','type','value']).stack()).reset_index().set_index('date')\n",
    "df.columns=['type','value','lang','langtype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slicing governance2 from 2021-04-09 00:00:00+00:00 ...\n",
      "Writing to governance2 ...\n",
      "0 data points will be written in 0.0 batches.\n",
      "Expected query running time is: 3 seconds.\n",
      "Writing batch 1 ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "field_columns=['value']\n",
    "tag_columns=['type','lang','langtype']\n",
    "measurement='governance2'\n",
    "# push2influx(df.replace(0,np.nan).dropna(),measurement,field_columns,tag_columns,fo=True)\n",
    "push2influx(df.replace(0,np.nan).dropna(),measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='minidashboard'\n",
    "dm=pd.read_csv(url+sheet)\n",
    "df=df0[list(dl.columns)].dropna(how='all')\n",
    "df=df.loc[~df.index.isnull()]\n",
    "for i in dm.set_index('ID')['UI'].iteritems():\n",
    "    df[i[0]]=i[1]\n",
    "sheet='EcMonitor'\n",
    "du=pd.read_csv(url+sheet)\n",
    "du=du.set_index('date').loc['Unemployment ratio'][2:].dropna()\n",
    "du.index=[(pd.to_datetime('now')-pd.to_timedelta('11D')*(1+i)).strftime('%Y-%m-%d') for i in range(len(du))][::-1]\n",
    "du=pd.DataFrame(du)\n",
    "du.columns=['unemployment']\n",
    "du.index=pd.to_datetime(du.index)\n",
    "df=df.join(du)\n",
    "sheet='employmentdata'\n",
    "de=pd.read_csv(url+sheet)\n",
    "de['date']=pd.to_datetime(de['date'])\n",
    "de=de[de.columns[:3]].set_index('date')\n",
    "de.columns=['felbontott','felfuggesztett']\n",
    "# df=df.join(de.ffill())\n",
    "for c in de.columns:\n",
    "    de[c]=de[c].astype(str).str.replace(',','').str.replace('%','').astype(float)#.interpolate(method='linear').dropna()\n",
    "df=df.join(de)\n",
    "df=df.join(mobility_mini)\n",
    "for c in df.columns:\n",
    "    df[c]=df[c].astype(str).str.replace(',','').str.replace('%','').astype(float)\n",
    "sheet='exchangerates'\n",
    "dx=pd.read_csv(url+sheet)\n",
    "dx=dx[['date','EUR - RON (megváltozás)']][5:-1]\n",
    "dx['date']=pd.to_datetime(dx['date'])\n",
    "dx=dx.set_index('date')\n",
    "dx.columns=['xch']\n",
    "dx['xch']=dx['xch'].astype(str).str.replace(',','').str.replace('%','').astype(float).sort_index().cumsum()\n",
    "df=df.join(dx)\n",
    "df['xch']=df['xch'].ffill()\n",
    "sheet='stocks_all'\n",
    "dk=pd.read_csv(url+sheet)[bets].dropna()\n",
    "dk['date']=pd.to_datetime(dk[bets[0]])\n",
    "dk=dk.set_index('date').drop(bets[0],axis=1)\n",
    "dk.columns=['bet']\n",
    "dk=dk.reindex(df.index)\n",
    "dk['bet']=dk['bet'].astype(str).str.replace(',','').str.replace('%','').astype(float).sort_index().cumsum()\n",
    "df=df.join(dk)\n",
    "sheet='MiniGDP'\n",
    "dg=pd.read_csv(url+sheet)\n",
    "dg1=dg[['Date','GDP (QoQ, SA)']].dropna()\n",
    "dg1.index=[(pd.to_datetime('now')-pd.to_timedelta('2D')*(1+i)).strftime('%Y-%m-%d') for i in range(len(dg1))][::-1]\n",
    "dg2=dg[['Date.1','GDP']].dropna()\n",
    "dg2.index=[(pd.to_datetime('now')-pd.to_timedelta('8D')*(1+i)).strftime('%Y-%m-%d') for i in range(len(dg2))][::-1]\n",
    "sheet='DFMChartYoY'\n",
    "dg3=pd.read_csv(url+sheet).T\n",
    "dg3=pd.read_csv(url+sheet,skiprows=19,nrows=2).T.iloc[1:].dropna()[1]\n",
    "dg3.index=[(pd.to_datetime('now')-pd.to_timedelta('1D')*(1+i)).strftime('%Y-%m-%d') for i in range(len(dg3))][::-1]\n",
    "dg=dg1.join(dg2).join(dg3)[['GDP','GDP (QoQ, SA)',1]].astype(float)\n",
    "dg.columns=['gdp','gdpq','employees']\n",
    "dg.index=pd.to_datetime(dg.index)\n",
    "df=df.join(dg)\n",
    "df=df[:pd.to_datetime('now')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slicing governance3 from 2021-04-09 00:00:00+00:00 ...\n",
      "Writing to governance3 ...\n",
      "0 data points will be written in 0.0 batches.\n",
      "Expected query running time is: 3 seconds.\n",
      "Writing batch 1 ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "field_columns=list(df.columns)\n",
    "tag_columns=[]\n",
    "measurement='governance3'\n",
    "# push2influx(df,measurement,field_columns,tag_columns,wo=True,fo=True)\n",
    "push2influx(df,measurement,field_columns,tag_columns,wo=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grafana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('408', 73819, '09', '10:02')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today0=now[-2:]\n",
    "if today0[0]=='0': \n",
    "    today=today0[1]\n",
    "else:\n",
    "    today=today0\n",
    "currents=str(current)[:-3]+'&nbsp;'+str(current)[-3:]\n",
    "hour=str(pd.to_datetime('now')+pd.to_timedelta('3h'))[11:16]\n",
    "str(szotar['report']['UI'][1:]),current,today0,hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def darken2(color):\n",
    "    return '#'+str(hex(int(\"0x\"+color[1:], 16) & 0xfefefe >> 1))[2:]\n",
    "def brighten2(color):\n",
    "    return '#'+str(hex(int(\"0x\"+color[1:], 16) & 0x7f7f7f << 1))[2:]\n",
    "def adjust_lightness(color, amount=0.5):\n",
    "    import matplotlib.colors as mc\n",
    "    import colorsys\n",
    "    try:\n",
    "        c = mc.cnames[color]\n",
    "    except:\n",
    "        c = color\n",
    "    c = colorsys.rgb_to_hls(*mc.to_rgb(c))\n",
    "    return mc.rgb2hex(colorsys.hls_to_rgb(c[0], max(0, min(1, amount * c[1])), c[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# szotardf,szotar,szotarHU,szotarRO,szotarEN=get_szotar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_to_darken=['#F2CC0C','#CA95E5','#FF780A','#E0B400','#96D98D','#F2495C','#E02F44',\n",
    "                  'lime','#73BF69','#8AB8FF','#3274D9','#D3D3D3','#FF7383','#FADE2A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "top=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iso_counties=pd.read_html('https://en.wikipedia.org/wiki/Counties_of_Romania')[1]\\\n",
    "#     .set_index(['ISO code[note 3]'])['County'].to_dict()\n",
    "# iso_counties['BN']='Bistrița-Năsăud'\n",
    "# iso_counties['CL']='Călărași'\n",
    "# open(htmlipath+'panels/iso_counties.json','w').write(json.dumps(iso_counties))\n",
    "iso_counties=json.loads(open(htmlipath+'panels/iso_counties.json','r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "georo=json.loads(open(htmlipath+'panels/romania-counties.json','r').read())\n",
    "georoco={i['properties']['NAME_1']:i['properties']['ID_1'] for i in georo['objects']['ROU_adm1']['geometries']}   \n",
    "georoco['București']=georoco['Bucharest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='industry_county'\n",
    "df=pd.read_csv(url+sheet)[:-2]\n",
    "df=df[df.columns[:5]]\n",
    "df.columns=['HU','RO','EN','q2','q3']\n",
    "for q in ['q2','q3']:\n",
    "    df[q]=df[q].str.replace('%','').astype(float)\n",
    "df=df.set_index('RO').join(pd.DataFrame(georoco,index=['county']).T).reset_index().dropna()\n",
    "df.columns=['RO','HU','EN','q2','q3','county']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-61-1a3a71a98fd4>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ddd[c+'_high']=True\n",
      "<ipython-input-61-1a3a71a98fd4>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ddd[c+'_high']=False\n"
     ]
    }
   ],
   "source": [
    "for lang in languages:\n",
    "    dc=df[[lang,'q2','q3','county']]\n",
    "    dc.columns=['county','q2','q3','id']\n",
    "    for c in ['q2','q3']:\n",
    "        dd=dc.set_index([c])[['county']].sort_index(ascending=False)\n",
    "        dds=[]\n",
    "        ddd=dd.iloc[:top]\n",
    "        ddd[c+'_high']=True\n",
    "        dds.append(ddd)\n",
    "        ddd=dd.iloc[-top:]\n",
    "        ddd[c+'_high']=False\n",
    "        dds.append(ddd)\n",
    "        dds=pd.concat(dds)\n",
    "        dds[c+'_display']=True\n",
    "        dc=dc.set_index(['county']).join(dds.reset_index().set_index(['county'])\\\n",
    "                                         [[c+'_display',c+'_high']]).reset_index()\n",
    "        dc[c+'_display']=dc[c+'_display'].fillna(False)\n",
    "        \n",
    "    dcqs=[]\n",
    "    for c in ['q2','q3']:\n",
    "        dcq=dc.set_index([c,'county'])[[c+'_display',c+'_high']]\n",
    "        dcq.index.names=['value','county']\n",
    "        dcq['quarter']=c\n",
    "        dcq=dcq.reset_index().set_index(['quarter','county','value'])\n",
    "        dcq.columns=['display','high']\n",
    "        dcq['high']=dcq['high'].fillna(False)\n",
    "        dcqs.append(dcq)\n",
    "    dcqs=pd.concat(dcqs)\n",
    "    dcc=dc.set_index(['county','id'])[['q2','q3']].stack().reset_index()\n",
    "    dcc.columns=['county','id','quarter','value']\n",
    "    dcc=dcc.set_index(['quarter','county','value']).join(dcqs).reset_index()\n",
    "    dcc['q']=dcc['quarter'].replace({'q2':'Q2 vs Q1','q3':'Q3 vs Q2'})\n",
    "    dcc['q0']=dcc['quarter'].replace({'q2':2019,'q3':2020})\n",
    "    # dcc=dcc.sort_values('quarter',ascending=False)\n",
    "    open(htmlipath+'panels/county_'+lang+'.json','w').write(json.dumps(list(dcc.T.to_dict().values())))\n",
    "    # open('county_'+lang+'.json','w').write(json.dumps(list(dc.T.to_dict().values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case county map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet='counties_current'\n",
    "dg=pd.read_csv(url+sheet, header=None)\n",
    "dgl=dg[[1,4]].set_index(4).T.to_dict()\n",
    "dgl['Dambovita']=dgl['Dâmbovita']\n",
    "dgl['Szucsáva']=dgl['Suceava']\n",
    "dgl['Galac']=dgl['Galati']\n",
    "dgl['Valcea']=dgl['Vâlcea']\n",
    "dfl=df[languages+['county']].set_index('HU')\n",
    "dh=dfl.join(pd.DataFrame(dgl).T).reset_index().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in languages:\n",
    "    dc=dh[[lang,1,'county']]\n",
    "    dc.columns=['county','value','id']\n",
    "    open(htmlipath+'panels/county2_'+lang+'.json','w').write(json.dumps(list(dc.T.to_dict().values())))\n",
    "    # open('county2_'+lang+'.json','w').write(json.dumps(list(dc.T.to_dict().values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case county map fancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop=json.loads(open(htmlipath+'panels/pop.json').read())\n",
    "pop={i:pop[i][1] for i in pop}\n",
    "pdf=pd.DataFrame(pop,index=['pop']).T\n",
    "pdf.index.name='iso'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dq=pd.DataFrame(dlz_counties).groupby('date').mean().drop('-',axis=1).stack().reset_index()\n",
    "dq.columns=['date','iso','cases']\n",
    "iso2=pd.DataFrame(iso_counties,index=['EN']).T.reset_index()\n",
    "iso2.columns=['iso','EN']\n",
    "dq=dq.set_index('iso').join(pdf).join(iso2.set_index('iso')).set_index('EN').join(dh.set_index('EN').drop(1,axis=1)).reset_index()\n",
    "dq['case_cap']=dq['cases']*1000/dq['pop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-66-0c1092ac59e8>:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d['county']='d'\n",
      "<ipython-input-66-0c1092ac59e8>:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d['case_14_cap']=4\n",
      "<ipython-input-66-0c1092ac59e8>:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d['id']=99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-66-0c1092ac59e8>:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d['county']='d'\n",
      "<ipython-input-66-0c1092ac59e8>:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d['case_14_cap']=4\n",
      "<ipython-input-66-0c1092ac59e8>:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d['id']=99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-66-0c1092ac59e8>:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d['county']='d'\n",
      "<ipython-input-66-0c1092ac59e8>:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d['case_14_cap']=4\n",
      "<ipython-input-66-0c1092ac59e8>:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d['id']=99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN\n"
     ]
    }
   ],
   "source": [
    "dmss=[]\n",
    "for lang in languages:\n",
    "    dms=[]\n",
    "    # dm=dq.set_index([lang,'date'])[['cases','case_cap','pop','county']]\n",
    "    dm=dq.set_index('EN').join(iso2.set_index('EN')).reset_index().set_index([lang,'date'])[['cases','case_cap','pop','county','iso']]\n",
    "    for m in dm.index.get_level_values(0).unique():\n",
    "        dc=dm.loc[m].sort_index()\n",
    "        p=dc.iloc[0]['pop']\n",
    "        dc['case_14']=dc['cases'].diff().rolling(14).sum()\n",
    "        dc['case_14_cap']=dc['case_14']*1000/p\n",
    "        dc['id']=dc['county']\n",
    "        dc['county']=m\n",
    "        dms.append(dc.dropna())\n",
    "    dms=pd.concat(dms)\n",
    "    dms=dms[((dms['case_14_cap']<14)&(dms['case_14_cap']>0))] #filter out non-sense values\n",
    "    open(htmlipath+'panels/county2c_'+lang+'.json','w').write(json.dumps(list(dms.reset_index().T.to_dict().values())))\n",
    "    dms2=dms.sort_index()['2020-08-05':]\n",
    "    open(htmlipath+'panels/county2d_'+lang+'.json','w').write(json.dumps(list(dms2.reset_index().T.to_dict().values())))\n",
    "    \n",
    "    dc=dms.reset_index().sort_index(ascending=False)\n",
    "    for c in ['cases','case_cap','case_14','case_14_cap']:\n",
    "        dd=dc.reset_index().set_index(['date',c])[['county']].sort_index(ascending=False)\n",
    "        dds=[]\n",
    "        for d in dd.index.get_level_values(0).unique():\n",
    "            dds.append(dd.loc[[d]].iloc[:top])\n",
    "            dds.append(dd.loc[[d]].iloc[-top:])\n",
    "        dds=pd.concat(dds)\n",
    "        dds[c+'_display']=True\n",
    "        dc=dc.set_index(['date','county']).join(dds.reset_index().set_index(['date','county'])[c+'_display']).reset_index()\n",
    "        dc[c+'_display']=dc[c+'_display'].fillna(False)\n",
    "        \n",
    "    d=dc.iloc[[0]]\n",
    "    d['county']='d'\n",
    "    d['case_14_cap']=4\n",
    "    d['id']=99\n",
    "        \n",
    "    open(htmlipath+'panels/county2b_'+lang+'.json','w').write(json.dumps(list(d.T.to_dict().values())+list(dc.T.to_dict().values())))\n",
    "    open(htmlipath+'panels/daily/county2b_'+latest+'_'+lang+'.json','w').write(json.dumps(list(d.T.to_dict().values())+list(dc.T.to_dict().values())))\n",
    "    dms['lang']=lang\n",
    "    dmss.append(dms)\n",
    "    print(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16605"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_counties2=open(htmlipath+'panels/cases_counties2.html','r').read()\n",
    "cases_counties2=cases_counties2[:cases_counties2.find('daily/county2b_\\' + \\'2021-')+20]+latest+cases_counties2[cases_counties2.find('daily/county2b_\\' + \\'2021-')+30:]\n",
    "open(htmlipath+'panels/cases_counties2.html','w').write(cases_counties2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counties per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dz=dh.set_index('EN').join(pd.DataFrame(pd.DataFrame(iso_counties,index=['county'])\\\n",
    "                                     .T.reset_index().set_index('county'))).reset_index()\n",
    "dlz_data=pd.DataFrame(pd.DataFrame(dlz_counties).groupby('date').mean().stack()).reset_index()\n",
    "dlz_data.columns=['date','index','value']\n",
    "dz=dlz_data.set_index('index').join(dz.set_index('index')).dropna().set_index('date')\n",
    "dz.index=pd.to_datetime(dz.index)\n",
    "dz2=dz.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dz2=dz2.ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dz=pd.DataFrame(dz.set_index(['county','value',1],append=True).stack()).reset_index()\n",
    "dz.columns=['date','county','value','dump','lang','langtype']\n",
    "dz=dz.set_index('date').drop('dump',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slicing counties from 2021-04-09 00:00:00+00:00 ...\n",
      "Writing to counties ...\n",
      "0 data points will be written in 0.0 batches.\n",
      "Expected query running time is: 3 seconds.\n",
      "Writing batch 1 ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "field_columns=['value']\n",
    "tag_columns=['lang','langtype']\n",
    "measurement='counties'\n",
    "push2influx(dz,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counties active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dz2=dz2.reset_index().set_index(['EN','HU','RO','county',1,'date'])\\\n",
    "    .unstack().diff(axis=1).stack().reset_index().set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dz2=pd.DataFrame(dz2.set_index(['county','value',1],append=True).stack()).reset_index()\n",
    "dz2.columns=['date','county','value','dump','lang','langtype']\n",
    "dz2=dz2.set_index('date').drop('dump',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slicing counties2 from 2021-04-09 00:00:00+00:00 ...\n",
      "Writing to counties2 ...\n",
      "0 data points will be written in 0.0 batches.\n",
      "Expected query running time is: 3 seconds.\n",
      "Writing batch 1 ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "field_columns=['value']\n",
    "tag_columns=['lang','langtype']\n",
    "measurement='counties2'\n",
    "push2influx(dz2,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "County intensity map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmsr=pd.concat(dmss)[['case_14_cap','county','iso','lang']]\n",
    "dmsr.index=pd.to_datetime(dmsr.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slicing counties3 from 2021-04-09 00:00:00+00:00 ...\n",
      "Writing to counties3 ...\n",
      "0 data points will be written in 0.0 batches.\n",
      "Expected query running time is: 3 seconds.\n",
      "Writing batch 1 ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "field_columns=['case_14_cap']\n",
    "tag_columns=['county','iso','lang']\n",
    "measurement='counties3'\n",
    "push2influx(dmsr,measurement,field_columns,tag_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locality map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagov1a=pd.read_excel('https://data.gov.ro/dataset/b86a78a3-7f88-4b53-a94f-015082592466/resource/bc19c354-644d-4a24-a26f-512129dbc70d/download/transparenta_vaccinare_martie_2021.xlsx')\n",
    "datagov2a=pd.read_excel('https://data.gov.ro/dataset/b86a78a3-7f88-4b53-a94f-015082592466/resource/d0b60b45-fb08-4980-a34c-8cbb4a43cad3/download/transparenta_martie_2021.xlsx',skiprows=1)\n",
    "datagov1b=pd.read_excel('https://data.gov.ro/dataset/b86a78a3-7f88-4b53-a94f-015082592466/resource/a0eb9ff2-9b97-430c-b285-360cadb55307/download/vaccinare-covid19-grupe-risc-01-01.04.2021.xlsx')\n",
    "datagov2b=pd.read_excel('https://data.gov.ro/dataset/b86a78a3-7f88-4b53-a94f-015082592466/resource/d3280256-07cc-4f93-957a-9815085899be/download/transparenta_aprilie_2021.xlsx',skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagov1=pd.concat([datagov1a,datagov1b])\n",
    "datagov2=datagov2a.set_index(['Judet','UAT']).join(datagov2b.set_index(['Judet','UAT'])).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "del datagov1a\n",
    "del datagov1b\n",
    "del datagov2a\n",
    "del datagov2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "uat=json.loads(open(htmlipath+'panels/uat_simplificat.geojson','r').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs=[]\n",
    "for f in uat['features']:\n",
    "    locs.append(f['properties'])\n",
    "locs=pd.DataFrame(locs)[['judet','uat','siruta']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judetconverter(c):\n",
    "    return (' '.join([i.capitalize() for i in c.split(' ')])).replace('ţ','ț').replace('ş','ș').replace('năsăud','Năsăud').\\\n",
    "        replace('severin','Severin').replace('mare','Mare').\\\n",
    "        replace('Municipiul București','Bucharest').replace('București','Bucharest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_iso=pd.DataFrame(iso_counties,index=['index']).T.reset_index().set_index('index').join(\\\n",
    "    pd.DataFrame(georoco,index=['geo_id']).T.reset_index().set_index('index')).reset_index()\n",
    "geo_iso.columns=['en','iso2','geo_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs['judet_norm']=[judetconverter(i) for i in locs['judet']]\n",
    "datagov2['judet_norm']=[judetconverter(i) for i in datagov2['Judet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uatconverter(judet,c):\n",
    "    c=(' '.join(['-'.join([b.capitalize() for b in a.split('-')]) for a in c.split(' ')]))\\\n",
    "        .replace('ţ','ț').replace('ş','ș').replace('Ţ','Ț').replace('Ş','Ș')\\\n",
    "        .replace('î','â').replace(' De ',' de ')\\\n",
    "        .replace('Cuza Voda','Cuza Vodă')\n",
    "    \n",
    "    if (judet=='Dolj'):\n",
    "        c=c.replace('Segarcea','Șegarcea')\n",
    "    elif (judet=='Teleorman'):\n",
    "        c=c.replace('Turnu Magurele','Turnu Măgurele')\n",
    "    elif (judet=='Olt'):\n",
    "        c=c.replace('Ipotesti','Ipotești')\n",
    "    elif (judet=='Alba'):\n",
    "        c=c.replace('Râmetea','Rimetea')\n",
    "    elif (judet=='Constanța'):\n",
    "        c=c.replace('44066','')\n",
    "    elif (judet=='Ialomița'):\n",
    "        c=c.replace('Radulești','Rădulești')\n",
    "    elif (judet=='Argeș'):\n",
    "        c=c.replace('Ciofringeni','Ciofrângeni')\\\n",
    "        .replace('Valea Mare Pravăț','Valea Mare-Pravăț')\n",
    "    elif (judet=='Vâlcea'):\n",
    "        c=c.replace('Păusești-Măglași','Păușești-Măglași')\n",
    "    elif (judet=='Prahova'):\n",
    "        c=c.replace('Cocorastii Colt','Cocorăștii Colț')\n",
    "    elif (judet=='Bucharest'):\n",
    "        c=c.replace('București Sectorul','Sector')\n",
    "    elif (judet=='Gorj'):\n",
    "        c=c.replace('Crușet','Crușeț')\n",
    "    elif (judet=='Brăila'):\n",
    "        c=c.replace('Racoviță','Racovița')\\\n",
    "        .replace('Gradiștea','Grădiștea')\\\n",
    "        .replace('Chișcani','Chiscani')\n",
    "    elif (judet=='Cluj'):\n",
    "        c=c.replace('Râșca','Rișca')\n",
    "    elif (judet=='Botoșani'):\n",
    "        c=c.replace('Răușeni','Răuseni')\n",
    "    elif (judet=='Maramureș'):\n",
    "        c=c.replace('Șisești','Șișești')\n",
    "    elif (judet=='Brașov'):\n",
    "        c=c.replace('Sambata de Sus','Sâmbăta de Sus')\n",
    "    elif (judet=='Vaslui'):\n",
    "        c=c.replace('Tătărăni','Tătărani')\n",
    "    elif (judet=='Iași'):\n",
    "        c=c.replace('Țigănăși','Țigănași')\n",
    "    elif (judet=='Bistrița-Năsăud'):\n",
    "        c=c.replace('Ilva Mica','Ilva Mică')\n",
    "    elif (judet=='Bihor'):\n",
    "        c=c.replace('Sănnicolau Romăn','Sânnicolau Român')\n",
    "    elif (judet=='Mureș'):\n",
    "        c=c.replace('Sarmașu','Sărmașu')\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagov2['uat_norm']=[(' '.join(['-'.join([b.capitalize() for b in a.split('-')]) for a in u.split(' ')]))\\\n",
    "                      .replace('ţ','ț').replace('ş','ș').replace('Ţ','Ț').replace('Ş','Ș')\\\n",
    "                      .replace(' De ',' de ').replace('Municipiul ','').replace('Oraș ','')\\\n",
    "                      for u in datagov2['UAT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constanța 44066 \n",
      "  \n"
     ]
    }
   ],
   "source": [
    "uat_norms=[]\n",
    "for judet in locs['judet_norm'].unique():\n",
    "    for l in locs[locs['judet_norm']==judet]['uat'].unique():\n",
    "        u=uatconverter(judet,str(l))\n",
    "        if u not in datagov2[datagov2['judet_norm']==judet]['uat_norm'].unique():\n",
    "            u=u.replace(' ','-')\n",
    "            if u not in datagov2[datagov2['judet_norm']==judet]['uat_norm'].unique():\n",
    "                print(judet,l,u)\n",
    "                u=''\n",
    "        uat_norms.append({'judet_norm':judet,'uat_norm':u,'uat':l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs2=locs.set_index(['judet_norm','uat']).join(pd.DataFrame(uat_norms).set_index(['judet_norm','uat'])).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagov3=datagov2.set_index(['judet_norm','uat_norm']).join(locs2.set_index(['judet_norm','uat_norm']))\n",
    "datagov3=datagov3.set_index(['judet','uat','siruta'],append=True).drop(['UAT','Judet'],axis=1)\n",
    "datagov3.index=datagov3.index.reorder_levels([2,3,4,0,1])\n",
    "# datagov3_dates=[pd.to_datetime(c) for c in datagov3.columns]\n",
    "# datagov3_dates=[c for c in datagov3.columns]\n",
    "datagov3_dates=[str(pd.to_datetime(c)) for c in datagov3.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagov3=datagov3.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "del datagov1\n",
    "del datagov2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat(r):\n",
    "    if r<1: return '< 1 ‰'\n",
    "    elif r<2: return '1-2 ‰'\n",
    "    elif r<4: return '2-4 ‰'\n",
    "    elif r<6: return '4-6 ‰'\n",
    "    elif r<8: return '6-8 ‰'\n",
    "    elif r<10: return '8-10 ‰'\n",
    "    elif r<20: return '> 10-20 ‰'\n",
    "    else: return '> 20 ‰'\n",
    "def cat2(r):\n",
    "    if r<1: return 0\n",
    "    elif r<2: return 1\n",
    "    elif r<4: return 2\n",
    "    elif r<6: return 3\n",
    "    elif r<8: return 4\n",
    "    elif r<10: return 5\n",
    "    elif r<20: return 6\n",
    "    else: return 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=0\n",
    "new_uat={'type':'FeatureCollection','features':[]}\n",
    "new_uat_numbers=[]\n",
    "new_uat_daily={'type':'FeatureCollection','features':[]}\n",
    "for i in range(len(uat['features'])):\n",
    "    dummy={}\n",
    "    judet=uat['features'][i]['properties']['judet']\n",
    "    if (judet!=''):\n",
    "        u=uat['features'][i]['properties']['uat']\n",
    "        siruta=uat['features'][i]['properties']['siruta']\n",
    "        # dummy={'judet':judet,'uat':u,'siruta':siruta}\n",
    "        if u in datagov3.loc[judet].index:\n",
    "            d=datagov3.loc[judet].loc[u].loc[siruta]\n",
    "            values=d.values[0]\n",
    "            dummy['🌄']=d.index[0][0]\n",
    "            dummy['🏠']=d.index[0][1]\n",
    "            for t in range(len(values)):\n",
    "                value=values[t]\n",
    "                date=datagov3_dates[t]\n",
    "                dummy['📈']=value\n",
    "                dummy['🔴']=cat(value)\n",
    "                dummy['⚫']=cat2(value)\n",
    "                dummy['📆']=date\n",
    "                feature={'type':'Feature','geometry':uat['features'][i]['geometry'],'properties':dummy.copy()}\n",
    "                new_uat['features'].append(feature)\n",
    "                new_uat_numbers.append(dummy.copy())\n",
    "                if (t==len(datagov3_dates)-1):\n",
    "                    new_uat_daily['features'].append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276910854"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(htmlipath+'panels/new_uat_numbers.json','w').write(json.dumps(new_uat_numbers))\n",
    "open(htmlipath+'panels/new_uat.json','w').write(json.dumps(new_uat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7100456"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Kepler.gl export\n",
    "open(htmlipath+'panels/daily/new_uat'+date[:10]+'.json','w').write(json.dumps(new_uat_daily))\n",
    "open(htmlipath+'panels/new_uat_daily.json','w').write(json.dumps(new_uat_daily))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "del new_uat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D3plus export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagov4=datagov3.stack().reset_index()\n",
    "datagov4.columns=['judet','uat','id','judet_norm','uat_norm','date','value']\n",
    "datagov4['value']=np.round(datagov4['value'],2)\n",
    "# datagov4=datagov4.dropna(subset=['judet'])\n",
    "datagov4=datagov4.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19389725"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(htmlipath+'panels/daily/uat2b_'+date[:10]+'.json','w').write(json.dumps(list(datagov4.T.to_dict().values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #HTML overwrite\n",
    "# cases_localities=open(htmlipath+'panels/cases_localities.html','r').read()\n",
    "# cases_localities=cases_localities[:cases_localities.find('daily/uat2b_\\' + \\'2021-')+17]+latest+cases_localities[cases_localities.find('daily/uat2b_\\' + \\'2021-')+27:]\n",
    "# open(htmlipath+'panels/cases_localities.html','w').write(cases_localities)\n",
    "# #### CHECK IF LATEST DATE IS ONE LESS than latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restrictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame(new_uat_numbers)\n",
    "df4=df2[['🌄', '🏠', '📈','📆']].set_index(['🌄', '🏠', '📆']).unstack()['📈'].sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restrictie(x,w):\n",
    "    if x>7.5: return 4\n",
    "    elif x>7:\n",
    "        if w>7.5: return 3\n",
    "        else: return 2\n",
    "    elif x>4: return 2\n",
    "    elif x>3.5:\n",
    "        if w>4: return 1\n",
    "        else: return 0\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def restrictie2(x,w):\n",
    "    if x>7.5: return '7.5+'\n",
    "    elif x>7:\n",
    "        if w>7.5: return '7.5-'\n",
    "        else: return '4+'\n",
    "    elif x>4: return '4+'\n",
    "    elif x>3.5:\n",
    "        if w>4: return '4-'\n",
    "        else: return '0'\n",
    "    else:\n",
    "        return '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr=[]\n",
    "for i in df4.T.iteritems():\n",
    "    v=i[1]\n",
    "    #print(i[0])\n",
    "    for j in range(len(v)):\n",
    "        t=v.index[j]\n",
    "        x=v[j]\n",
    "        y=v[j-min(14,j):j].values\n",
    "        w=x\n",
    "        if len(y):\n",
    "            w=max(y)\n",
    "        r=restrictie(x,w)\n",
    "        #print(j,t,x,w,r)\n",
    "        dr.append({'🌄':i[0][0], '🏠':i[0][1], '🚦':r,'📆':t})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp=pd.DataFrame(dr).set_index(['🌄', '🏠','📆']).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in new_uat_daily['features']:\n",
    "    i['properties']['🚦']=dp.loc[i['properties']['🌄']].loc[i['properties']['🏠']].loc[i['properties']['📆']]['🚦']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7167320"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(htmlipath+'panels/new_uat_daily2.json','w').write(json.dumps(new_uat_daily))\n",
    "open(htmlipath+'panels/daily/new_uat_daily2_'+date[:10]+'.json','w').write(json.dumps(new_uat_daily))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18658"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#HTML overwrite\n",
    "uat_html=open(htmlipath+'panels/daily/mapbox-'+date[:10]+'.html','r').read()\n",
    "uat_html=uat_html.replace(date[5:10],date[5:8]+today0).replace(date[5:10],date[5:8]+today0)\n",
    "uat_html=uat_html[:uat_html.find('.json')-2]+\\\n",
    "    str(pd.to_datetime(now)+pd.to_timedelta('-1d'))[8:10]+\\\n",
    "    uat_html[uat_html.find('.json'):]\n",
    "open(htmlipath+'panels/daily/mapbox-'+date[:8]+today0+'.html','w').write(uat_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload to `uat.json` to mapbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapbox colors:\n",
    "# 239e69\n",
    "# f5d232\n",
    "# c52b69\n",
    "# 850237"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add szekelydata GitHub update\n",
    "#Add mapbox direct upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>siruta</th>\n",
       "      <th>54975</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>judet_norm</th>\n",
       "      <th>Cluj</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uat_norm</th>\n",
       "      <th>Cluj-Napoca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-04-06</th>\n",
       "      <td>8.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-07</th>\n",
       "      <td>7.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-08</th>\n",
       "      <td>7.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "siruta           54975\n",
       "judet_norm        Cluj\n",
       "uat_norm   Cluj-Napoca\n",
       "2021-04-06        8.01\n",
       "2021-04-07        7.84\n",
       "2021-04-08        7.67"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity check\n",
    "datagov3.loc['Cluj'].loc['Cluj-Napoca'].T.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapbox upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapbox_api_key=open('auth/mapbox.txt','r').read()\n",
    "url='https://api.mapbox.com/styles/v1/<my_user>/<my_style>?access_token='+mapbox_api_key\n",
    "r=requests.get(url)\n",
    "mbstyle=json.loads(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbstyle['name']='<my_style_name>'\n",
    "# mbstyle['modified']=str(pd.to_datetime('now')).replace(' ','T')[:23]+'Z'\n",
    "mbstyle.pop('modified');\n",
    "mbstyle.pop('created');\n",
    "mbstyle['layers'][0]['paint']['fill-color'][4]='#ffee00'\n",
    "mbstyle['layers'][0]['paint']['fill-color'][10]='#ffffff'\n",
    "mbstyle['layers'][0]['paint']['fill-color'][2][1]='⚫'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head = {\"Content-Type\":\"application/json\"}\n",
    "r = requests.patch(url, json.dumps(mbstyle), headers=head)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json.loads(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait 5 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Push to Grafana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]> b'{\"id\":2,\"slug\":\"magyar\",\"status\":\"success\",\"uid\":\"hu\",\"url\":\"/d/hu/magyar\",\"version\":292}'\n",
      "<Response [200]> b'{\"id\":5,\"slug\":\"magyar-light\",\"status\":\"success\",\"uid\":\"hu-light\",\"url\":\"/d/hu-light/magyar-light\",\"version\":128}'\n",
      "<Response [200]> b'{\"id\":3,\"slug\":\"romana\",\"status\":\"success\",\"uid\":\"ro\",\"url\":\"/d/ro/romana\",\"version\":197}'\n",
      "<Response [200]> b'{\"id\":6,\"slug\":\"romana-light\",\"status\":\"success\",\"uid\":\"ro-light\",\"url\":\"/d/ro-light/romana-light\",\"version\":122}'\n",
      "<Response [200]> b'{\"id\":4,\"slug\":\"english\",\"status\":\"success\",\"uid\":\"en\",\"url\":\"/d/en/english\",\"version\":161}'\n",
      "<Response [200]> b'{\"id\":7,\"slug\":\"english-light\",\"status\":\"success\",\"uid\":\"en-light\",\"url\":\"/d/en-light/english-light\",\"version\":123}'\n"
     ]
    }
   ],
   "source": [
    "nevuto={'0':'á','1':'é','3':'á','2':'á','4':'é','5':'é','6':'á','7':'é','8':'á','9':'é'}\n",
    "for lang in languages:\n",
    "    response = requests.get(grafana+'api/dashboards/uid/'+lang.lower(), headers=headers)\n",
    "    model=json.loads(response.content)['dashboard']\n",
    "    for i in model['panels']:\n",
    "        if lang=='HU':\n",
    "            #print(i['id'],i['type'],i['title'])\n",
    "            if i['id'] in (179, 91):\n",
    "                i['options']['iframeURL']=i['options']['iframeURL'][:i['options']['iframeURL'].find('.html#')-2]+\\\n",
    "                    today0+i['options']['iframeURL'][i['options']['iframeURL'].find('.html#'):]\n",
    "                i['description']=i['description'][:i['description'].find('n,')-4].strip()+' '+today+'-'+\\\n",
    "                    nevuto[now[-1]]+i['description'][i['description'].find('n,'):\\\n",
    "                    i['description'].find(':')-2]+hour+\\\n",
    "                    i['description'][i['description'].find(':')+3:]\n",
    "                i['title']=i['title'][:i['title'].rfind(' ')]+' '+today\n",
    "            if i['id']==82:\n",
    "                i['content']=i['content'][:i['content'].find('<b>')+3]+str(szotar['report']['UI'][1:])+\\\n",
    "                    i['content'][i['content'].find('</b>'):i['content'].rfind('<b>')+3]+currents+\\\n",
    "                    i['content'][i['content'].rfind('</b>'):]\n",
    "            if i['id']==93:\n",
    "                i['content']=i['content'][:i['content'].rfind('</b>')-2]+today0+\\\n",
    "                i['content'][i['content'].rfind('</b>'):]\n",
    "        elif lang=='EN':\n",
    "            if i['id'] in (153, 91):\n",
    "                i['options']['iframeURL']=i['options']['iframeURL'][:i['options']['iframeURL'].find('.html#')-2]+\\\n",
    "                    today0+i['options']['iframeURL'][i['options']['iframeURL'].find('.html#'):]\n",
    "                i['description']=i['description'][:i['description'].find(':')-2]+hour+' on '+today+' '+ i['description'][i['description'].find('on ')+5:]\n",
    "                i['title']=i['title'][:i['title'].find('📆')+2]+today+i['title'][i['title'].find('📆')+3:]\n",
    "            if i['id']==82:\n",
    "                i['content']=i['content'][:i['content'].find('<b>')+3]+str(szotar['report']['UI'][1:])+\\\n",
    "                    i['content'][i['content'].find('</b>'):i['content'].rfind('<b>')+3]+currents+\\\n",
    "                    i['content'][i['content'].rfind('</b>'):]\n",
    "            if i['id']==93:\n",
    "                i['content']=i['content'][:i['content'].rfind('</b>')-2]+today0+\\\n",
    "                i['content'][i['content'].rfind('</b>'):]\n",
    "        elif lang=='RO':\n",
    "            if i['id'] in (153, 91):\n",
    "                i['options']['iframeURL']=i['options']['iframeURL'][:i['options']['iframeURL'].find('.html#')-2]+\\\n",
    "                    today0+i['options']['iframeURL'][i['options']['iframeURL'].find('.html#'):]\n",
    "                i['description']=i['description'][:i['description'].find(':')-2]+hour+' în data de '+today+' '+ i['description'][i['description'].find('în data de ')+13:]\n",
    "                i['title']=i['title'][:i['title'].find('📆')+2]+today+i['title'][i['title'].find('📆')+3:]\n",
    "            if i['id']==82:\n",
    "                i['content']=i['content'][:i['content'].find('<b>')+3]+str(szotar['report']['UI'][1:])+\\\n",
    "                    i['content'][i['content'].find('</b>'):i['content'].rfind('<b>')+3]+currents+\\\n",
    "                    i['content'][i['content'].rfind('</b>'):]\n",
    "            if i['id']==93:\n",
    "                i['content']=i['content'][:i['content'].rfind('<b>')+3]+today0+\\\n",
    "                i['content'][i['content'].rfind('<b>')+5:]\n",
    "            \n",
    "    r=requests.post(grafana+'api/dashboards/db', headers=headers, json={\"dashboard\":model,\n",
    "                                                                            \"folderId\": folder_id,\n",
    "                                                                            \"overwrite\": True\n",
    "                                                                           })       \n",
    "    print(r,r.content)\n",
    "    open(lang+'.json','w').write(json.dumps(model))    \n",
    "    \n",
    "    model_light=json.dumps(model).replace('dark','light',9999).replace('lightGray','#52545C',9999)\\\n",
    "        .replace('#d3d3d3','#52545c',9999)\\\n",
    "        .replace('csaladen.es/favicon.ico\" style=\"','csaladen.es/favicon.ico\" style=\"filter: brightness(0.3);',9999)\n",
    "    for color in colors_to_darken:\n",
    "        model_light=model_light.replace(color,adjust_lightness(color,0.8),9999)\n",
    "        model_light=model_light.replace(color.lower(),adjust_lightness(color,0.8),9999)\n",
    "    model=json.loads(model_light)\n",
    "    model['title']=titles[lang]+' Light'\n",
    "    model['uid']=uids_light[lang]\n",
    "    model['id']=iids_light[lang]\n",
    "    r=requests.post(grafana+'api/dashboards/db', headers=headers, json={\"dashboard\":model,\n",
    "                                                                            \"folderId\": folder_id,\n",
    "                                                                            \"overwrite\": True\n",
    "                                                                           })    \n",
    "    print(r,r.content)\n",
    "    open(lang+'-light.json','w').write(json.dumps(model))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}