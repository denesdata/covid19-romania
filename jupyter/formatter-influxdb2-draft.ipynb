{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Included installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install influxdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install influxdb-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not included installs, but neessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install feedparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import json\n",
    "from influxdb_client import InfluxDBClient, Point, WritePrecision, WriteOptions\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "purge = False\n",
    "# purge=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_annoations = False\n",
    "# process_annoations=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_macro=False\n",
    "process_macro = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_out=False\n",
    "write_out = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_overwrite = False\n",
    "# full_overwrite=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pre-params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(\"df0.csv\").set_index(\"date\")\n",
    "df0.index = pd.to_datetime(df0.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bets = json.loads(open(\"bets.json\", \"r\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity = pd.read_csv(\"severity.csv\").set_index(\"date\")\n",
    "severity.index = pd.to_datetime(severity.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobility = pd.read_csv(\"mobility.csv\").set_index(\"date\")\n",
    "mobility.index = pd.to_datetime(mobility.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobility_mini = pd.read_csv(\"mobility_mini.csv\").set_index(\"date\")\n",
    "mobility_mini.index = pd.to_datetime(mobility_mini.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish DB connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"admin\"\n",
    "token = open(\"auth/influxb.txt\", \"r\").read()\n",
    "org = \"roeim\"\n",
    "bucket = \"base\"\n",
    "# write_api = client.write_api(write_options=SYNCHRONOUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if purge:\n",
    "    client = InfluxDBClient(url=\"http://influxdb:8086\", token=token)\n",
    "    delete_api = client.delete_api()\n",
    "    start = str(pd.to_datetime(\"1970-01-02\")).replace(\" \", \"T\") + \"Z\"\n",
    "    stop = str(pd.to_datetime(\"now\")).replace(\" \", \"T\") + \"Z\"\n",
    "    delete_api.delete(start, stop, \"\", bucket=bucket, org=org)\n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "htmlipath = \"../html/\"\n",
    "htmlepath = \"//myserv.er/\"\n",
    "htmlepath_other = \"//mybackupserv.er/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = {\"HU\": \"Magyar\", \"RO\": \"Română\", \"EN\": \"English\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtitles = {titles[t]: t for t in titles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "grafana = \"http://grafana:3000/\"\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer \" + open(\"auth/grafana.txt\", \"r\").read(),\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(grafana + \"api/folders\", headers=headers)\n",
    "folders = json.loads(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_id = [f[\"id\"] for f in folders if f[\"title\"] == \"My Grafana Folder\"][0] #General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(grafana+'api/search?folderIds='+str(folder_id), headers=headers)\n",
    "dashs = json.loads(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "uids = {rtitles[d[\"title\"]]: d[\"uid\"] for d in dashs if d[\"title\"] in rtitles}\n",
    "iids = {rtitles[d[\"title\"]]: d[\"id\"] for d in dashs if d[\"title\"] in rtitles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "uids_light = {\n",
    "    rtitles[d[\"title\"].split(\" Light\")[0]]: d[\"uid\"]\n",
    "    for d in dashs\n",
    "    if \"Light\" in d[\"title\"]\n",
    "}\n",
    "iids_light = {\n",
    "    rtitles[d[\"title\"].split(\" Light\")[0]]: d[\"id\"]\n",
    "    for d in dashs\n",
    "    if \"Light\" in d[\"title\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = [\"HU\", \"RO\", \"EN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://docs.google.com/spreadsheets/d/'+open('auth/sheet.txt','r').read()+'/gviz/tq?tqx=out:csv&sheet='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_szotar():\n",
    "    sheet = \"szotar\"\n",
    "    columns = (\n",
    "        languages\n",
    "        + [i + \"_description\" for i in languages]\n",
    "        + [i + \"_source\" for i in languages]\n",
    "    )\n",
    "    df = pd.read_csv(url + sheet)\n",
    "    df = df[[\"ID\", \"UI\"] + columns]\n",
    "    sheet = \"minidashboard\"\n",
    "    df2 = pd.read_csv(url + sheet)\n",
    "    df2 = df2[[\"ID\", \"UI\"] + columns]\n",
    "    df = pd.concat([df, df2])\n",
    "    szotardf = df.set_index(\"ID\")[columns]\n",
    "    szotar = df.set_index(\"ID\").T.to_dict()\n",
    "    szotarHU = df.set_index(\"HU\", drop=False).T.to_dict()\n",
    "    szotarRO = df.set_index(\"RO\", drop=False).T.to_dict()\n",
    "    szotarEN = df.set_index(\"EN\", drop=False).T.to_dict()\n",
    "    return szotardf, szotar, szotarHU, szotarRO, szotarEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_time_conflicts(series):\n",
    "    ds = {}\n",
    "    ts = []\n",
    "    for d in series:\n",
    "        if d not in ds:\n",
    "            ds[d] = pd.to_datetime(d)\n",
    "            t = ds[d]\n",
    "        else:\n",
    "            ds[d] = ds[d] + pd.to_timedelta(\"193m\")\n",
    "            t = ds[d]\n",
    "        ts.append(t)\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-77652dbc15c9>:12: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  szotarHU=df.set_index('HU',drop=False).T.to_dict()\n",
      "<ipython-input-34-77652dbc15c9>:13: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  szotarRO=df.set_index('RO',drop=False).T.to_dict()\n",
      "<ipython-input-34-77652dbc15c9>:14: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  szotarEN=df.set_index('EN',drop=False).T.to_dict()\n"
     ]
    }
   ],
   "source": [
    "szotardf, szotar, szotarHU, szotarRO, szotarEN = get_szotar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "utc = pytz.UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push2influx(\n",
    "    df,\n",
    "    measurement,\n",
    "    field_columns,\n",
    "    tag_columns,\n",
    "    shift=False,\n",
    "    wo=write_out,\n",
    "    fo=full_overwrite,\n",
    "    daily=True,\n",
    "    bucket=\"base\",\n",
    "):\n",
    "    if wo:\n",
    "        client = InfluxDBClient(url=\"http://influxdb:8086\", token=token)\n",
    "        write_api = client.write_api(\n",
    "            write_options=WriteOptions(\n",
    "                batch_size=1000,\n",
    "                flush_interval=10_000,\n",
    "                jitter_interval=2_000,\n",
    "                retry_interval=5_000,\n",
    "            )\n",
    "        )\n",
    "        df = df.sort_index()\n",
    "        # df.index = utc.localize(df.index)\n",
    "        df.index = df.index.tz_localize(\"GMT\")  # .tz_convert('Europe/Bucharest')\n",
    "        if shift:\n",
    "            df.index += pd.to_timedelta(\"12h\")\n",
    "        if fo:\n",
    "            pass\n",
    "            delete_api = client.delete_api()\n",
    "            start = str(pd.to_datetime(\"1970-01-02\")).replace(\" \", \"T\") + \"Z\"\n",
    "            stop = str(pd.to_datetime(\"now\")).replace(\" \", \"T\") + \"Z\"\n",
    "            delete_api.delete(\n",
    "                start,\n",
    "                stop,\n",
    "                '_measurement=\"' + measurement + '\"',\n",
    "                bucket=bucket,\n",
    "                org=org,\n",
    "            )\n",
    "        else:\n",
    "            query = \"\"\"\n",
    "                from(bucket: \"base\")\n",
    "                |> range(start:-25h, stop: now())\n",
    "                |> filter(fn: (r) => r._measurement == \"\"\"+'\"'+ measurement +'\"'\n",
    "            latest = client.query_api().query_data_frame(org=org, query=query)\n",
    "            if \"_time\" in latest.columns:\n",
    "                lat = latest[\"_time\"][0]\n",
    "                if daily:\n",
    "                    lat += pd.to_timedelta(\"1d\")\n",
    "                df = df[lat:]\n",
    "                print(\"Slicing\", measurement, \"from\", lat, \"...\")\n",
    "            else:\n",
    "                print(\"No data in db for\", measurement, \"...\")\n",
    "        time.sleep(3)\n",
    "        print(\"Writing to\", measurement, \"...\")\n",
    "        write_api.write(\n",
    "            bucket,\n",
    "            org=org,\n",
    "            record=df[field_columns + tag_columns],\n",
    "            data_frame_measurement_name=measurement,\n",
    "            data_frame_tag_columns=tag_columns,\n",
    "        )\n",
    "        time.sleep(2)\n",
    "        client.close()\n",
    "        print(\"Done!\")\n",
    "    else:\n",
    "        print(\"Write-out not enabled. Skipping...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DateLaZi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new method from DateLaZi\n",
    "dlz = requests.get(\"https://datelazi.ro/latestData.json\").content\n",
    "dlz = json.loads(dlz)\n",
    "dlz[\"historicalData\"][dlz[\"currentDayStats\"][\"parsedOnString\"]] = dlz[\"currentDayStats\"]\n",
    "dlzs = []\n",
    "dlz_counties = []\n",
    "for date in dlz[\"historicalData\"]:\n",
    "    d = {}\n",
    "    mdate = (\n",
    "        date.replace(\"2018-11-07\", \"2020-11-07\")\n",
    "        .replace(\"2020-01-05\", \"2021-01-05\")\n",
    "        .replace(\"2020-01-07\", \"2021-01-07\")\n",
    "    )\n",
    "    d[\"date\"] = mdate\n",
    "    d[\"cases\"] = dlz[\"historicalData\"][date][\"numberInfected\"]\n",
    "    d[\"heals\"] = dlz[\"historicalData\"][date][\"numberCured\"]\n",
    "    d[\"deaths\"] = dlz[\"historicalData\"][date][\"numberDeceased\"]\n",
    "    if \"vaccines\" in dlz[\"historicalData\"][date]:\n",
    "        if dlz[\"historicalData\"][date][\"vaccines\"]:\n",
    "            for v in dlz[\"historicalData\"][date][\"vaccines\"]:\n",
    "                for k in [\"total_administered\", \"immunized\"]:\n",
    "                    k2 = k.replace(\"immunized\", \"total_immunized\")\n",
    "                    if k2 not in d:\n",
    "                        d[k2] = 0\n",
    "                    d[k2] += dlz[\"historicalData\"][date][\"vaccines\"][v][k]\n",
    "                    d[k2 + \"_\" + v] = dlz[\"historicalData\"][date][\"vaccines\"][v][k]\n",
    "    if \"countyInfectionsNumbers\" in dlz[\"historicalData\"][date]:\n",
    "        counties = dlz[\"historicalData\"][date][\"countyInfectionsNumbers\"]\n",
    "        if counties:\n",
    "            for county in counties:\n",
    "                dlz_counties.append(\n",
    "                    {\n",
    "                        \"date\": mdate,\n",
    "                        county: dlz[\"historicalData\"][date][\"countyInfectionsNumbers\"][\n",
    "                            county\n",
    "                        ],\n",
    "                    }\n",
    "                )\n",
    "    dlzs.append(d)\n",
    "dl = pd.DataFrame(dlzs).set_index(\"date\").sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in dl.columns[3:]:\n",
    "    dl[c] = dl[c].cumsum()\n",
    "dl2 = dl.diff()\n",
    "dl2.columns = [\"case\", \"heal\", \"death\"] + [\n",
    "    i.replace(\"total_\", \"\") for i in dl2.columns[3:]\n",
    "]\n",
    "dl[\"active\"] = dl[\"cases\"] - dl[\"heals\"] - dl[\"deaths\"]\n",
    "dl = dl.join(dl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-28 2021-03-29\n"
     ]
    }
   ],
   "source": [
    "latest = dl.index[-1]\n",
    "now = str(pd.to_datetime(\"now\"))[:10]\n",
    "print(latest, now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests from `graphs.ro`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-26\n"
     ]
    }
   ],
   "source": [
    "r = requests.get(\"https://www.graphs.ro/json.php\")\n",
    "graphs_ro = json.loads(r.content)[\"covid_romania\"]\n",
    "g = pd.DataFrame(graphs_ro)\n",
    "# g['date']=pd.to_datetime(g['reporting_date'])\n",
    "g[\"date\"] = g[\"reporting_date\"]\n",
    "g = g.set_index(\"date\")\n",
    "g[\"tests\"] = g[\"total_tests\"]\n",
    "g[\"test\"] = g[\"new_tests_today\"]\n",
    "latest2 = g.index[0]\n",
    "print(latest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-26\n"
     ]
    }
   ],
   "source": [
    "latest = str(min(pd.to_datetime(latest), pd.to_datetime(latest2)))[:10]\n",
    "print(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = dl.join(g[[\"tests\", \"test\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Governance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet = \"governance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(url + sheet)\n",
    "df = df.set_index(\"date\").sort_index(ascending=True).dropna(how=\"all\")\n",
    "df = df.join(dl, lsuffix=\"_g\")  # [20:] #[:-1] vaccines nincs a governance-ban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill from local, if missing in DateLaZi\n",
    "for c in [\"active\", \"cases\", \"heals\", \"deaths\", \"case\", \"heal\", \"death\"]:\n",
    "    df[c] = (\n",
    "        df[c]\n",
    "        .fillna(df[c + \"_g\"].astype(str).str.replace(\",\", \"\"))\n",
    "        .replace(\"nan\", np.nan)\n",
    "    )\n",
    "df = df.dropna(how=\"all\", axis=0).dropna(how=\"all\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df14 = df[[\"cases\"]].reset_index().join(df[[\"cases\"]][14:].reset_index(), lsuffix=\"1\")\n",
    "df14[\"case14\"] = df14[\"cases\"].astype(float) - df14[\"cases1\"].astype(float)\n",
    "df = df.join(df14.set_index(\"date\")[\"case14\"].dropna().astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(df.index)\n",
    "df0 = df.copy()\n",
    "vaccine_totals = [\n",
    "    i\n",
    "    for i in list(dl2.columns[3:]) + list(dl.columns[3 : len(dl2.columns)])\n",
    "    if \"total_\" in i\n",
    "]\n",
    "df = (\n",
    "    pd.DataFrame(\n",
    "        df[[\"active\", \"cases\", \"heals\", \"deaths\", \"case14\"] + vaccine_totals].stack()\n",
    "    )\n",
    "    .reset_index()\n",
    "    .set_index(\"date\")\n",
    ")\n",
    "df.columns = [\"type\", \"value\"]\n",
    "df[\"value\"] = df[\"value\"].astype(str).str.replace(\",\", \"\").astype(float).astype(int)\n",
    "df = df.join(szotardf, on=\"type\")\n",
    "df = (\n",
    "    pd.DataFrame(df.reset_index().set_index([\"date\", \"type\", \"value\"]).stack())\n",
    "    .reset_index()\n",
    "    .set_index(\"date\")\n",
    ")\n",
    "df.columns = [\"type\", \"value\", \"lang\", \"langtype\"]\n",
    "current = df[df[\"type\"] == \"case14\"][\"value\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.to_csv(\"df0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df0=pd.read_csv('df0.csv').set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Run till here to test Grafana only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to governance1 ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "field_columns = [\"value\"]\n",
    "tag_columns = [\"type\", \"lang\", \"langtype\"]\n",
    "measurement = \"governance1\"\n",
    "# push2influx(df.replace(0,np.nan).dropna(),measurement,field_columns,tag_columns,fo=True)\n",
    "push2influx(df.replace(0, np.nan).dropna(), measurement, field_columns, tag_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df0.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daily cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"case/test\"] = (\n",
    "    100\n",
    "    * df[\"case\"].astype(str).str.replace(\",\", \"\").astype(float)\n",
    "    / df[\"test\"].astype(str).str.replace(\",\", \"\").astype(float)\n",
    ")\n",
    "df[\"death_rate\"] = (\n",
    "    100\n",
    "    * df[\"death\"].astype(str).str.replace(\",\", \"\").astype(float)\n",
    "    / df[\"case\"].astype(str).str.replace(\",\", \"\").astype(float)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    pd.DataFrame(df[[\"death\", \"heal\", \"case\", \"case/test\", \"death_rate\"]].stack())\n",
    "    .reset_index()\n",
    "    .set_index(\"date\")\n",
    ")\n",
    "df.columns = [\"type\", \"value\"]\n",
    "df[\"value\"] = df[\"value\"].astype(str).str.replace(\",\", \"\").astype(float)\n",
    "df = df.join(szotardf, on=\"type\")\n",
    "df = (\n",
    "    pd.DataFrame(df.reset_index().set_index([\"date\", \"type\", \"value\"]).stack())\n",
    "    .reset_index()\n",
    "    .set_index(\"date\")\n",
    ")\n",
    "df.columns = [\"type\", \"value\", \"lang\", \"langtype\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to governance2 ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "field_columns = [\"value\"]\n",
    "tag_columns = [\"type\", \"lang\", \"langtype\"]\n",
    "measurement = \"governance2\"\n",
    "# push2influx(df.replace(0,np.nan).dropna(),measurement,field_columns,tag_columns,fo=True)\n",
    "push2influx(df.replace(0, np.nan).dropna(), measurement, field_columns, tag_columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}